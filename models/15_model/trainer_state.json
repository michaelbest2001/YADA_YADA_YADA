{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.999204455051711,
  "eval_steps": 200,
  "global_step": 7855,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006364359586316627,
      "grad_norm": 0.4076956808567047,
      "learning_rate": 5.089058524173028e-06,
      "loss": 2.4735,
      "step": 10
    },
    {
      "epoch": 0.012728719172633254,
      "grad_norm": 0.28017184138298035,
      "learning_rate": 1.0178117048346055e-05,
      "loss": 2.4476,
      "step": 20
    },
    {
      "epoch": 0.01909307875894988,
      "grad_norm": 0.39511746168136597,
      "learning_rate": 1.5267175572519086e-05,
      "loss": 2.5443,
      "step": 30
    },
    {
      "epoch": 0.02545743834526651,
      "grad_norm": 0.3656884729862213,
      "learning_rate": 2.035623409669211e-05,
      "loss": 2.5309,
      "step": 40
    },
    {
      "epoch": 0.031821797931583136,
      "grad_norm": 0.3372531533241272,
      "learning_rate": 2.5445292620865142e-05,
      "loss": 2.3048,
      "step": 50
    },
    {
      "epoch": 0.03818615751789976,
      "grad_norm": 0.37909576296806335,
      "learning_rate": 3.053435114503817e-05,
      "loss": 2.2865,
      "step": 60
    },
    {
      "epoch": 0.04455051710421639,
      "grad_norm": 0.5252281427383423,
      "learning_rate": 3.56234096692112e-05,
      "loss": 2.3282,
      "step": 70
    },
    {
      "epoch": 0.05091487669053302,
      "grad_norm": 0.45676523447036743,
      "learning_rate": 4.071246819338422e-05,
      "loss": 2.3367,
      "step": 80
    },
    {
      "epoch": 0.057279236276849645,
      "grad_norm": 0.49793609976768494,
      "learning_rate": 4.5801526717557256e-05,
      "loss": 2.2796,
      "step": 90
    },
    {
      "epoch": 0.06364359586316627,
      "grad_norm": 0.5276049971580505,
      "learning_rate": 5.0890585241730283e-05,
      "loss": 2.1854,
      "step": 100
    },
    {
      "epoch": 0.07000795544948289,
      "grad_norm": 0.612518846988678,
      "learning_rate": 5.597964376590331e-05,
      "loss": 2.1878,
      "step": 110
    },
    {
      "epoch": 0.07637231503579953,
      "grad_norm": 0.6979292631149292,
      "learning_rate": 6.106870229007635e-05,
      "loss": 2.148,
      "step": 120
    },
    {
      "epoch": 0.08273667462211615,
      "grad_norm": 0.5908947587013245,
      "learning_rate": 6.615776081424937e-05,
      "loss": 2.1857,
      "step": 130
    },
    {
      "epoch": 0.08910103420843278,
      "grad_norm": 0.6416109800338745,
      "learning_rate": 7.12468193384224e-05,
      "loss": 2.0654,
      "step": 140
    },
    {
      "epoch": 0.0954653937947494,
      "grad_norm": 0.7600832581520081,
      "learning_rate": 7.633587786259542e-05,
      "loss": 2.1231,
      "step": 150
    },
    {
      "epoch": 0.10182975338106603,
      "grad_norm": 0.9680341482162476,
      "learning_rate": 8.142493638676844e-05,
      "loss": 2.2458,
      "step": 160
    },
    {
      "epoch": 0.10819411296738266,
      "grad_norm": 0.7961456179618835,
      "learning_rate": 8.651399491094148e-05,
      "loss": 2.1007,
      "step": 170
    },
    {
      "epoch": 0.11455847255369929,
      "grad_norm": 0.7715678215026855,
      "learning_rate": 9.160305343511451e-05,
      "loss": 2.0563,
      "step": 180
    },
    {
      "epoch": 0.12092283214001591,
      "grad_norm": 0.6791610717773438,
      "learning_rate": 9.669211195928753e-05,
      "loss": 2.0588,
      "step": 190
    },
    {
      "epoch": 0.12728719172633254,
      "grad_norm": 0.777953028678894,
      "learning_rate": 0.00010178117048346057,
      "loss": 2.0983,
      "step": 200
    },
    {
      "epoch": 0.12728719172633254,
      "eval_loss": 2.1471002101898193,
      "eval_runtime": 148.2392,
      "eval_samples_per_second": 4.715,
      "eval_steps_per_second": 0.594,
      "step": 200
    },
    {
      "epoch": 0.13365155131264916,
      "grad_norm": 0.835925281047821,
      "learning_rate": 0.00010687022900763359,
      "loss": 2.0687,
      "step": 210
    },
    {
      "epoch": 0.14001591089896578,
      "grad_norm": 0.8916588425636292,
      "learning_rate": 0.00011195928753180662,
      "loss": 2.0583,
      "step": 220
    },
    {
      "epoch": 0.14638027048528243,
      "grad_norm": 0.9002471566200256,
      "learning_rate": 0.00011704834605597966,
      "loss": 2.0342,
      "step": 230
    },
    {
      "epoch": 0.15274463007159905,
      "grad_norm": 0.7899821996688843,
      "learning_rate": 0.0001221374045801527,
      "loss": 2.1474,
      "step": 240
    },
    {
      "epoch": 0.15910898965791567,
      "grad_norm": 0.9042071104049683,
      "learning_rate": 0.0001272264631043257,
      "loss": 2.0609,
      "step": 250
    },
    {
      "epoch": 0.1654733492442323,
      "grad_norm": 0.9393659234046936,
      "learning_rate": 0.00013231552162849873,
      "loss": 2.096,
      "step": 260
    },
    {
      "epoch": 0.1718377088305489,
      "grad_norm": 0.7089618444442749,
      "learning_rate": 0.00013740458015267177,
      "loss": 1.9563,
      "step": 270
    },
    {
      "epoch": 0.17820206841686556,
      "grad_norm": 0.7630752921104431,
      "learning_rate": 0.0001424936386768448,
      "loss": 1.9408,
      "step": 280
    },
    {
      "epoch": 0.18456642800318218,
      "grad_norm": 0.6497052907943726,
      "learning_rate": 0.00014758269720101784,
      "loss": 2.109,
      "step": 290
    },
    {
      "epoch": 0.1909307875894988,
      "grad_norm": 0.7143946290016174,
      "learning_rate": 0.00015267175572519084,
      "loss": 1.9713,
      "step": 300
    },
    {
      "epoch": 0.19729514717581542,
      "grad_norm": 0.6428136229515076,
      "learning_rate": 0.00015776081424936388,
      "loss": 2.0233,
      "step": 310
    },
    {
      "epoch": 0.20365950676213207,
      "grad_norm": 0.7680895924568176,
      "learning_rate": 0.00016284987277353689,
      "loss": 1.9502,
      "step": 320
    },
    {
      "epoch": 0.2100238663484487,
      "grad_norm": 0.7355201840400696,
      "learning_rate": 0.00016793893129770992,
      "loss": 2.0023,
      "step": 330
    },
    {
      "epoch": 0.2163882259347653,
      "grad_norm": 0.5994493365287781,
      "learning_rate": 0.00017302798982188295,
      "loss": 1.9532,
      "step": 340
    },
    {
      "epoch": 0.22275258552108193,
      "grad_norm": 0.6366394758224487,
      "learning_rate": 0.000178117048346056,
      "loss": 1.9811,
      "step": 350
    },
    {
      "epoch": 0.22911694510739858,
      "grad_norm": 0.7243441343307495,
      "learning_rate": 0.00018320610687022902,
      "loss": 2.141,
      "step": 360
    },
    {
      "epoch": 0.2354813046937152,
      "grad_norm": 0.6705161333084106,
      "learning_rate": 0.00018829516539440203,
      "loss": 1.9564,
      "step": 370
    },
    {
      "epoch": 0.24184566428003182,
      "grad_norm": 0.6431901454925537,
      "learning_rate": 0.00019338422391857506,
      "loss": 2.0824,
      "step": 380
    },
    {
      "epoch": 0.24821002386634844,
      "grad_norm": 0.725095272064209,
      "learning_rate": 0.0001984732824427481,
      "loss": 2.0865,
      "step": 390
    },
    {
      "epoch": 0.2545743834526651,
      "grad_norm": 0.6302081346511841,
      "learning_rate": 0.00019981238273921202,
      "loss": 1.96,
      "step": 400
    },
    {
      "epoch": 0.2545743834526651,
      "eval_loss": 2.110093355178833,
      "eval_runtime": 148.1942,
      "eval_samples_per_second": 4.717,
      "eval_steps_per_second": 0.594,
      "step": 400
    },
    {
      "epoch": 0.2609387430389817,
      "grad_norm": 0.6616816520690918,
      "learning_rate": 0.00019954435808094346,
      "loss": 2.0533,
      "step": 410
    },
    {
      "epoch": 0.26730310262529833,
      "grad_norm": 0.5680224299430847,
      "learning_rate": 0.00019927633342267488,
      "loss": 1.9896,
      "step": 420
    },
    {
      "epoch": 0.273667462211615,
      "grad_norm": 0.6623379588127136,
      "learning_rate": 0.00019900830876440633,
      "loss": 2.0207,
      "step": 430
    },
    {
      "epoch": 0.28003182179793157,
      "grad_norm": 0.681734561920166,
      "learning_rate": 0.00019874028410613777,
      "loss": 2.0264,
      "step": 440
    },
    {
      "epoch": 0.2863961813842482,
      "grad_norm": 0.6330171227455139,
      "learning_rate": 0.00019847225944786921,
      "loss": 1.9803,
      "step": 450
    },
    {
      "epoch": 0.29276054097056486,
      "grad_norm": 0.5579504370689392,
      "learning_rate": 0.00019820423478960066,
      "loss": 2.0554,
      "step": 460
    },
    {
      "epoch": 0.29912490055688146,
      "grad_norm": 0.5993661284446716,
      "learning_rate": 0.0001979362101313321,
      "loss": 1.9955,
      "step": 470
    },
    {
      "epoch": 0.3054892601431981,
      "grad_norm": 0.4896419048309326,
      "learning_rate": 0.00019766818547306355,
      "loss": 1.909,
      "step": 480
    },
    {
      "epoch": 0.3118536197295147,
      "grad_norm": 0.6736481785774231,
      "learning_rate": 0.00019740016081479497,
      "loss": 2.025,
      "step": 490
    },
    {
      "epoch": 0.31821797931583135,
      "grad_norm": 0.7180073857307434,
      "learning_rate": 0.0001971321361565264,
      "loss": 2.0695,
      "step": 500
    },
    {
      "epoch": 0.324582338902148,
      "grad_norm": 0.5618150234222412,
      "learning_rate": 0.00019686411149825786,
      "loss": 1.9737,
      "step": 510
    },
    {
      "epoch": 0.3309466984884646,
      "grad_norm": 0.6890844106674194,
      "learning_rate": 0.0001965960868399893,
      "loss": 2.013,
      "step": 520
    },
    {
      "epoch": 0.33731105807478123,
      "grad_norm": 0.8007650375366211,
      "learning_rate": 0.00019632806218172072,
      "loss": 1.9842,
      "step": 530
    },
    {
      "epoch": 0.3436754176610978,
      "grad_norm": 0.7527143955230713,
      "learning_rate": 0.00019606003752345216,
      "loss": 2.0335,
      "step": 540
    },
    {
      "epoch": 0.3500397772474145,
      "grad_norm": 0.8845875263214111,
      "learning_rate": 0.0001957920128651836,
      "loss": 2.0651,
      "step": 550
    },
    {
      "epoch": 0.3564041368337311,
      "grad_norm": 0.718919038772583,
      "learning_rate": 0.00019552398820691505,
      "loss": 2.0462,
      "step": 560
    },
    {
      "epoch": 0.3627684964200477,
      "grad_norm": 0.544614851474762,
      "learning_rate": 0.00019525596354864647,
      "loss": 2.033,
      "step": 570
    },
    {
      "epoch": 0.36913285600636436,
      "grad_norm": 0.5571421980857849,
      "learning_rate": 0.00019498793889037791,
      "loss": 2.0204,
      "step": 580
    },
    {
      "epoch": 0.375497215592681,
      "grad_norm": 0.4941085875034332,
      "learning_rate": 0.00019471991423210936,
      "loss": 2.0026,
      "step": 590
    },
    {
      "epoch": 0.3818615751789976,
      "grad_norm": 0.6079293489456177,
      "learning_rate": 0.0001944518895738408,
      "loss": 2.038,
      "step": 600
    },
    {
      "epoch": 0.3818615751789976,
      "eval_loss": 2.0909013748168945,
      "eval_runtime": 148.179,
      "eval_samples_per_second": 4.717,
      "eval_steps_per_second": 0.594,
      "step": 600
    },
    {
      "epoch": 0.38822593476531425,
      "grad_norm": 0.5923557281494141,
      "learning_rate": 0.00019418386491557222,
      "loss": 1.9253,
      "step": 610
    },
    {
      "epoch": 0.39459029435163084,
      "grad_norm": 0.5360485315322876,
      "learning_rate": 0.00019391584025730367,
      "loss": 1.9864,
      "step": 620
    },
    {
      "epoch": 0.4009546539379475,
      "grad_norm": 0.5949508547782898,
      "learning_rate": 0.0001936478155990351,
      "loss": 1.9915,
      "step": 630
    },
    {
      "epoch": 0.40731901352426414,
      "grad_norm": 0.5806036591529846,
      "learning_rate": 0.00019337979094076658,
      "loss": 2.0645,
      "step": 640
    },
    {
      "epoch": 0.41368337311058073,
      "grad_norm": 0.5855922698974609,
      "learning_rate": 0.000193111766282498,
      "loss": 1.9952,
      "step": 650
    },
    {
      "epoch": 0.4200477326968974,
      "grad_norm": 0.5272858142852783,
      "learning_rate": 0.00019284374162422945,
      "loss": 1.903,
      "step": 660
    },
    {
      "epoch": 0.42641209228321403,
      "grad_norm": 0.5787646770477295,
      "learning_rate": 0.0001925757169659609,
      "loss": 2.0512,
      "step": 670
    },
    {
      "epoch": 0.4327764518695306,
      "grad_norm": 0.5223110914230347,
      "learning_rate": 0.00019230769230769233,
      "loss": 1.942,
      "step": 680
    },
    {
      "epoch": 0.43914081145584727,
      "grad_norm": 0.6671502590179443,
      "learning_rate": 0.00019203966764942375,
      "loss": 1.9962,
      "step": 690
    },
    {
      "epoch": 0.44550517104216386,
      "grad_norm": 0.5434412956237793,
      "learning_rate": 0.0001917716429911552,
      "loss": 1.935,
      "step": 700
    },
    {
      "epoch": 0.4518695306284805,
      "grad_norm": 0.6979119181632996,
      "learning_rate": 0.00019150361833288664,
      "loss": 2.118,
      "step": 710
    },
    {
      "epoch": 0.45823389021479716,
      "grad_norm": 0.6493777632713318,
      "learning_rate": 0.00019123559367461809,
      "loss": 1.9095,
      "step": 720
    },
    {
      "epoch": 0.46459824980111375,
      "grad_norm": 0.581716001033783,
      "learning_rate": 0.0001909675690163495,
      "loss": 1.9226,
      "step": 730
    },
    {
      "epoch": 0.4709626093874304,
      "grad_norm": 0.5026478171348572,
      "learning_rate": 0.00019069954435808095,
      "loss": 1.9834,
      "step": 740
    },
    {
      "epoch": 0.477326968973747,
      "grad_norm": 0.6729504466056824,
      "learning_rate": 0.0001904315196998124,
      "loss": 1.9955,
      "step": 750
    },
    {
      "epoch": 0.48369132856006364,
      "grad_norm": 0.5114887356758118,
      "learning_rate": 0.00019016349504154384,
      "loss": 1.9029,
      "step": 760
    },
    {
      "epoch": 0.4900556881463803,
      "grad_norm": 0.574741005897522,
      "learning_rate": 0.00018989547038327526,
      "loss": 1.8988,
      "step": 770
    },
    {
      "epoch": 0.4964200477326969,
      "grad_norm": 0.6231647729873657,
      "learning_rate": 0.0001896274457250067,
      "loss": 2.0447,
      "step": 780
    },
    {
      "epoch": 0.5027844073190135,
      "grad_norm": 0.6376180648803711,
      "learning_rate": 0.00018935942106673815,
      "loss": 2.0439,
      "step": 790
    },
    {
      "epoch": 0.5091487669053302,
      "grad_norm": 0.5492521524429321,
      "learning_rate": 0.0001890913964084696,
      "loss": 1.9505,
      "step": 800
    },
    {
      "epoch": 0.5091487669053302,
      "eval_loss": 2.0759222507476807,
      "eval_runtime": 147.9441,
      "eval_samples_per_second": 4.725,
      "eval_steps_per_second": 0.595,
      "step": 800
    },
    {
      "epoch": 0.5155131264916468,
      "grad_norm": 0.6553892493247986,
      "learning_rate": 0.000188823371750201,
      "loss": 2.0607,
      "step": 810
    },
    {
      "epoch": 0.5218774860779634,
      "grad_norm": 0.5479217767715454,
      "learning_rate": 0.00018855534709193248,
      "loss": 1.9974,
      "step": 820
    },
    {
      "epoch": 0.52824184566428,
      "grad_norm": 0.6216973066329956,
      "learning_rate": 0.00018828732243366392,
      "loss": 1.9328,
      "step": 830
    },
    {
      "epoch": 0.5346062052505967,
      "grad_norm": 0.5364043712615967,
      "learning_rate": 0.00018801929777539534,
      "loss": 1.982,
      "step": 840
    },
    {
      "epoch": 0.5409705648369133,
      "grad_norm": 0.7995675802230835,
      "learning_rate": 0.00018775127311712679,
      "loss": 1.977,
      "step": 850
    },
    {
      "epoch": 0.54733492442323,
      "grad_norm": 0.516190767288208,
      "learning_rate": 0.00018748324845885823,
      "loss": 1.9335,
      "step": 860
    },
    {
      "epoch": 0.5536992840095465,
      "grad_norm": 0.665172278881073,
      "learning_rate": 0.00018721522380058968,
      "loss": 1.9319,
      "step": 870
    },
    {
      "epoch": 0.5600636435958631,
      "grad_norm": 0.533913254737854,
      "learning_rate": 0.0001869471991423211,
      "loss": 1.9828,
      "step": 880
    },
    {
      "epoch": 0.5664280031821798,
      "grad_norm": 0.5846664309501648,
      "learning_rate": 0.00018667917448405254,
      "loss": 1.9681,
      "step": 890
    },
    {
      "epoch": 0.5727923627684964,
      "grad_norm": 0.5270056128501892,
      "learning_rate": 0.00018641114982578398,
      "loss": 1.9852,
      "step": 900
    },
    {
      "epoch": 0.5791567223548131,
      "grad_norm": 0.5730303525924683,
      "learning_rate": 0.00018614312516751543,
      "loss": 1.9406,
      "step": 910
    },
    {
      "epoch": 0.5855210819411297,
      "grad_norm": 0.7489520311355591,
      "learning_rate": 0.00018587510050924685,
      "loss": 2.0711,
      "step": 920
    },
    {
      "epoch": 0.5918854415274463,
      "grad_norm": 0.645869791507721,
      "learning_rate": 0.0001856070758509783,
      "loss": 1.9719,
      "step": 930
    },
    {
      "epoch": 0.5982498011137629,
      "grad_norm": 0.5689901113510132,
      "learning_rate": 0.00018533905119270973,
      "loss": 2.0111,
      "step": 940
    },
    {
      "epoch": 0.6046141607000796,
      "grad_norm": 0.5575609803199768,
      "learning_rate": 0.00018507102653444118,
      "loss": 1.9591,
      "step": 950
    },
    {
      "epoch": 0.6109785202863962,
      "grad_norm": 0.7180997133255005,
      "learning_rate": 0.0001848030018761726,
      "loss": 1.9139,
      "step": 960
    },
    {
      "epoch": 0.6173428798727129,
      "grad_norm": 0.5001200437545776,
      "learning_rate": 0.00018453497721790404,
      "loss": 2.0377,
      "step": 970
    },
    {
      "epoch": 0.6237072394590294,
      "grad_norm": 0.4413132071495056,
      "learning_rate": 0.00018426695255963549,
      "loss": 1.9374,
      "step": 980
    },
    {
      "epoch": 0.630071599045346,
      "grad_norm": 0.49587827920913696,
      "learning_rate": 0.00018399892790136693,
      "loss": 1.9062,
      "step": 990
    },
    {
      "epoch": 0.6364359586316627,
      "grad_norm": 0.4512125849723816,
      "learning_rate": 0.00018373090324309838,
      "loss": 1.9006,
      "step": 1000
    },
    {
      "epoch": 0.6364359586316627,
      "eval_loss": 2.0696423053741455,
      "eval_runtime": 148.2196,
      "eval_samples_per_second": 4.716,
      "eval_steps_per_second": 0.594,
      "step": 1000
    },
    {
      "epoch": 0.6428003182179793,
      "grad_norm": 1.393123984336853,
      "learning_rate": 0.00018346287858482982,
      "loss": 2.0167,
      "step": 1010
    },
    {
      "epoch": 0.649164677804296,
      "grad_norm": 0.5621206164360046,
      "learning_rate": 0.00018319485392656127,
      "loss": 1.9722,
      "step": 1020
    },
    {
      "epoch": 0.6555290373906125,
      "grad_norm": 0.5182187557220459,
      "learning_rate": 0.0001829268292682927,
      "loss": 1.8641,
      "step": 1030
    },
    {
      "epoch": 0.6618933969769292,
      "grad_norm": 0.49740123748779297,
      "learning_rate": 0.00018265880461002413,
      "loss": 1.9534,
      "step": 1040
    },
    {
      "epoch": 0.6682577565632458,
      "grad_norm": 0.535114586353302,
      "learning_rate": 0.00018239077995175557,
      "loss": 2.0017,
      "step": 1050
    },
    {
      "epoch": 0.6746221161495625,
      "grad_norm": 0.5842636823654175,
      "learning_rate": 0.00018212275529348702,
      "loss": 1.9395,
      "step": 1060
    },
    {
      "epoch": 0.6809864757358791,
      "grad_norm": 0.5475100874900818,
      "learning_rate": 0.00018185473063521846,
      "loss": 1.9457,
      "step": 1070
    },
    {
      "epoch": 0.6873508353221957,
      "grad_norm": 0.7147284150123596,
      "learning_rate": 0.00018158670597694988,
      "loss": 1.8224,
      "step": 1080
    },
    {
      "epoch": 0.6937151949085123,
      "grad_norm": 0.7077805399894714,
      "learning_rate": 0.00018131868131868132,
      "loss": 2.0273,
      "step": 1090
    },
    {
      "epoch": 0.700079554494829,
      "grad_norm": 0.63759845495224,
      "learning_rate": 0.00018105065666041277,
      "loss": 2.0511,
      "step": 1100
    },
    {
      "epoch": 0.7064439140811456,
      "grad_norm": 0.5176409482955933,
      "learning_rate": 0.0001807826320021442,
      "loss": 1.8439,
      "step": 1110
    },
    {
      "epoch": 0.7128082736674622,
      "grad_norm": 0.5662734508514404,
      "learning_rate": 0.00018051460734387563,
      "loss": 1.9623,
      "step": 1120
    },
    {
      "epoch": 0.7191726332537789,
      "grad_norm": 0.6668441891670227,
      "learning_rate": 0.00018024658268560708,
      "loss": 1.9082,
      "step": 1130
    },
    {
      "epoch": 0.7255369928400954,
      "grad_norm": 0.5589343905448914,
      "learning_rate": 0.00017997855802733852,
      "loss": 1.9219,
      "step": 1140
    },
    {
      "epoch": 0.7319013524264121,
      "grad_norm": 0.6635712385177612,
      "learning_rate": 0.00017971053336906997,
      "loss": 1.8718,
      "step": 1150
    },
    {
      "epoch": 0.7382657120127287,
      "grad_norm": 0.49072161316871643,
      "learning_rate": 0.00017944250871080138,
      "loss": 1.9229,
      "step": 1160
    },
    {
      "epoch": 0.7446300715990454,
      "grad_norm": 0.6325979232788086,
      "learning_rate": 0.00017917448405253283,
      "loss": 1.932,
      "step": 1170
    },
    {
      "epoch": 0.750994431185362,
      "grad_norm": 0.4732212722301483,
      "learning_rate": 0.0001789064593942643,
      "loss": 1.9901,
      "step": 1180
    },
    {
      "epoch": 0.7573587907716786,
      "grad_norm": 0.7153857946395874,
      "learning_rate": 0.00017863843473599572,
      "loss": 2.0219,
      "step": 1190
    },
    {
      "epoch": 0.7637231503579952,
      "grad_norm": 0.536879301071167,
      "learning_rate": 0.00017837041007772716,
      "loss": 1.9598,
      "step": 1200
    },
    {
      "epoch": 0.7637231503579952,
      "eval_loss": 2.061201333999634,
      "eval_runtime": 148.1722,
      "eval_samples_per_second": 4.717,
      "eval_steps_per_second": 0.594,
      "step": 1200
    },
    {
      "epoch": 0.7700875099443119,
      "grad_norm": 0.6006084680557251,
      "learning_rate": 0.0001781023854194586,
      "loss": 1.9936,
      "step": 1210
    },
    {
      "epoch": 0.7764518695306285,
      "grad_norm": 0.503198504447937,
      "learning_rate": 0.00017783436076119005,
      "loss": 1.9457,
      "step": 1220
    },
    {
      "epoch": 0.7828162291169452,
      "grad_norm": 0.6319276690483093,
      "learning_rate": 0.0001775663361029215,
      "loss": 1.9628,
      "step": 1230
    },
    {
      "epoch": 0.7891805887032617,
      "grad_norm": 0.6122879385948181,
      "learning_rate": 0.0001772983114446529,
      "loss": 1.9845,
      "step": 1240
    },
    {
      "epoch": 0.7955449482895783,
      "grad_norm": 0.5950721502304077,
      "learning_rate": 0.00017703028678638436,
      "loss": 1.8787,
      "step": 1250
    },
    {
      "epoch": 0.801909307875895,
      "grad_norm": 0.4878326952457428,
      "learning_rate": 0.0001767622621281158,
      "loss": 1.9984,
      "step": 1260
    },
    {
      "epoch": 0.8082736674622116,
      "grad_norm": 0.5456029176712036,
      "learning_rate": 0.00017649423746984725,
      "loss": 1.9796,
      "step": 1270
    },
    {
      "epoch": 0.8146380270485283,
      "grad_norm": 0.6941779255867004,
      "learning_rate": 0.00017622621281157867,
      "loss": 2.0102,
      "step": 1280
    },
    {
      "epoch": 0.8210023866348448,
      "grad_norm": 0.5740325450897217,
      "learning_rate": 0.0001759581881533101,
      "loss": 1.9675,
      "step": 1290
    },
    {
      "epoch": 0.8273667462211615,
      "grad_norm": 0.5339372754096985,
      "learning_rate": 0.00017569016349504155,
      "loss": 1.9708,
      "step": 1300
    },
    {
      "epoch": 0.8337311058074781,
      "grad_norm": 0.500671923160553,
      "learning_rate": 0.000175422138836773,
      "loss": 1.9161,
      "step": 1310
    },
    {
      "epoch": 0.8400954653937948,
      "grad_norm": 0.6109610199928284,
      "learning_rate": 0.00017515411417850442,
      "loss": 2.0271,
      "step": 1320
    },
    {
      "epoch": 0.8464598249801114,
      "grad_norm": 0.4749903380870819,
      "learning_rate": 0.00017488608952023586,
      "loss": 1.8462,
      "step": 1330
    },
    {
      "epoch": 0.8528241845664281,
      "grad_norm": 0.5595791339874268,
      "learning_rate": 0.0001746180648619673,
      "loss": 1.8687,
      "step": 1340
    },
    {
      "epoch": 0.8591885441527446,
      "grad_norm": 0.579463541507721,
      "learning_rate": 0.00017435004020369875,
      "loss": 1.9707,
      "step": 1350
    },
    {
      "epoch": 0.8655529037390612,
      "grad_norm": 0.5472500324249268,
      "learning_rate": 0.00017408201554543017,
      "loss": 2.0088,
      "step": 1360
    },
    {
      "epoch": 0.8719172633253779,
      "grad_norm": 0.5608121156692505,
      "learning_rate": 0.00017381399088716164,
      "loss": 1.8873,
      "step": 1370
    },
    {
      "epoch": 0.8782816229116945,
      "grad_norm": 0.618004560470581,
      "learning_rate": 0.00017354596622889309,
      "loss": 1.9446,
      "step": 1380
    },
    {
      "epoch": 0.8846459824980112,
      "grad_norm": 0.6484689116477966,
      "learning_rate": 0.0001732779415706245,
      "loss": 1.8968,
      "step": 1390
    },
    {
      "epoch": 0.8910103420843277,
      "grad_norm": 0.4922347068786621,
      "learning_rate": 0.00017300991691235595,
      "loss": 2.0279,
      "step": 1400
    },
    {
      "epoch": 0.8910103420843277,
      "eval_loss": 2.0624711513519287,
      "eval_runtime": 148.2287,
      "eval_samples_per_second": 4.716,
      "eval_steps_per_second": 0.594,
      "step": 1400
    },
    {
      "epoch": 0.8973747016706444,
      "grad_norm": 0.7667860388755798,
      "learning_rate": 0.0001727418922540874,
      "loss": 1.9557,
      "step": 1410
    },
    {
      "epoch": 0.903739061256961,
      "grad_norm": 0.5221579074859619,
      "learning_rate": 0.00017247386759581884,
      "loss": 2.0231,
      "step": 1420
    },
    {
      "epoch": 0.9101034208432777,
      "grad_norm": 0.5677781105041504,
      "learning_rate": 0.00017220584293755025,
      "loss": 1.9602,
      "step": 1430
    },
    {
      "epoch": 0.9164677804295943,
      "grad_norm": 0.5723047256469727,
      "learning_rate": 0.0001719378182792817,
      "loss": 1.9915,
      "step": 1440
    },
    {
      "epoch": 0.9228321400159109,
      "grad_norm": 0.6536173224449158,
      "learning_rate": 0.00017166979362101314,
      "loss": 1.9126,
      "step": 1450
    },
    {
      "epoch": 0.9291964996022275,
      "grad_norm": 0.6205106377601624,
      "learning_rate": 0.0001714017689627446,
      "loss": 1.8986,
      "step": 1460
    },
    {
      "epoch": 0.9355608591885441,
      "grad_norm": 0.6263031363487244,
      "learning_rate": 0.000171133744304476,
      "loss": 1.9968,
      "step": 1470
    },
    {
      "epoch": 0.9419252187748608,
      "grad_norm": 0.5490056276321411,
      "learning_rate": 0.00017086571964620745,
      "loss": 1.9442,
      "step": 1480
    },
    {
      "epoch": 0.9482895783611774,
      "grad_norm": 0.6093659400939941,
      "learning_rate": 0.0001705976949879389,
      "loss": 1.9075,
      "step": 1490
    },
    {
      "epoch": 0.954653937947494,
      "grad_norm": 0.6121035218238831,
      "learning_rate": 0.00017032967032967034,
      "loss": 1.9955,
      "step": 1500
    },
    {
      "epoch": 0.9610182975338106,
      "grad_norm": 0.6065130829811096,
      "learning_rate": 0.00017006164567140176,
      "loss": 1.9879,
      "step": 1510
    },
    {
      "epoch": 0.9673826571201273,
      "grad_norm": 0.5225502252578735,
      "learning_rate": 0.0001697936210131332,
      "loss": 1.922,
      "step": 1520
    },
    {
      "epoch": 0.9737470167064439,
      "grad_norm": 0.5467550158500671,
      "learning_rate": 0.00016952559635486465,
      "loss": 1.9497,
      "step": 1530
    },
    {
      "epoch": 0.9801113762927606,
      "grad_norm": 0.5373831391334534,
      "learning_rate": 0.0001692575716965961,
      "loss": 2.056,
      "step": 1540
    },
    {
      "epoch": 0.9864757358790772,
      "grad_norm": 0.601512610912323,
      "learning_rate": 0.00016898954703832754,
      "loss": 1.9493,
      "step": 1550
    },
    {
      "epoch": 0.9928400954653938,
      "grad_norm": 0.6834334135055542,
      "learning_rate": 0.00016872152238005898,
      "loss": 1.9836,
      "step": 1560
    },
    {
      "epoch": 0.9992044550517104,
      "grad_norm": 0.6356414556503296,
      "learning_rate": 0.00016845349772179043,
      "loss": 1.8889,
      "step": 1570
    },
    {
      "epoch": 1.005568814638027,
      "grad_norm": 0.578900933265686,
      "learning_rate": 0.00016818547306352187,
      "loss": 2.0512,
      "step": 1580
    },
    {
      "epoch": 1.0119331742243436,
      "grad_norm": 0.5140894055366516,
      "learning_rate": 0.0001679174484052533,
      "loss": 1.9799,
      "step": 1590
    },
    {
      "epoch": 1.0182975338106603,
      "grad_norm": 0.6193158626556396,
      "learning_rate": 0.00016764942374698473,
      "loss": 1.9621,
      "step": 1600
    },
    {
      "epoch": 1.0182975338106603,
      "eval_loss": 2.0537660121917725,
      "eval_runtime": 148.1021,
      "eval_samples_per_second": 4.72,
      "eval_steps_per_second": 0.594,
      "step": 1600
    },
    {
      "epoch": 1.0246618933969769,
      "grad_norm": 0.5731198191642761,
      "learning_rate": 0.00016738139908871618,
      "loss": 1.8691,
      "step": 1610
    },
    {
      "epoch": 1.0310262529832936,
      "grad_norm": 0.49157628417015076,
      "learning_rate": 0.00016711337443044762,
      "loss": 1.9106,
      "step": 1620
    },
    {
      "epoch": 1.0373906125696102,
      "grad_norm": 0.6704209446907043,
      "learning_rate": 0.00016684534977217904,
      "loss": 1.8576,
      "step": 1630
    },
    {
      "epoch": 1.0437549721559267,
      "grad_norm": 0.620263397693634,
      "learning_rate": 0.00016657732511391049,
      "loss": 1.8904,
      "step": 1640
    },
    {
      "epoch": 1.0501193317422435,
      "grad_norm": 0.5925108790397644,
      "learning_rate": 0.00016630930045564193,
      "loss": 1.9836,
      "step": 1650
    },
    {
      "epoch": 1.05648369132856,
      "grad_norm": 0.6045333743095398,
      "learning_rate": 0.00016604127579737337,
      "loss": 1.8287,
      "step": 1660
    },
    {
      "epoch": 1.0628480509148768,
      "grad_norm": 0.57118821144104,
      "learning_rate": 0.0001657732511391048,
      "loss": 1.9496,
      "step": 1670
    },
    {
      "epoch": 1.0692124105011933,
      "grad_norm": 0.5606492757797241,
      "learning_rate": 0.00016550522648083624,
      "loss": 1.8671,
      "step": 1680
    },
    {
      "epoch": 1.0755767700875098,
      "grad_norm": 0.6490119695663452,
      "learning_rate": 0.00016523720182256768,
      "loss": 1.8946,
      "step": 1690
    },
    {
      "epoch": 1.0819411296738266,
      "grad_norm": 0.5060118436813354,
      "learning_rate": 0.00016496917716429913,
      "loss": 1.865,
      "step": 1700
    },
    {
      "epoch": 1.0883054892601431,
      "grad_norm": 0.6702645421028137,
      "learning_rate": 0.00016470115250603054,
      "loss": 2.0248,
      "step": 1710
    },
    {
      "epoch": 1.09466984884646,
      "grad_norm": 0.5113612413406372,
      "learning_rate": 0.000164433127847762,
      "loss": 1.9325,
      "step": 1720
    },
    {
      "epoch": 1.1010342084327764,
      "grad_norm": 0.6432268023490906,
      "learning_rate": 0.00016416510318949346,
      "loss": 1.9315,
      "step": 1730
    },
    {
      "epoch": 1.107398568019093,
      "grad_norm": 0.6705940961837769,
      "learning_rate": 0.00016389707853122488,
      "loss": 1.9692,
      "step": 1740
    },
    {
      "epoch": 1.1137629276054097,
      "grad_norm": 0.585767924785614,
      "learning_rate": 0.00016362905387295632,
      "loss": 1.8968,
      "step": 1750
    },
    {
      "epoch": 1.1201272871917263,
      "grad_norm": 0.6830893158912659,
      "learning_rate": 0.00016336102921468777,
      "loss": 1.8849,
      "step": 1760
    },
    {
      "epoch": 1.126491646778043,
      "grad_norm": 0.5574328899383545,
      "learning_rate": 0.0001630930045564192,
      "loss": 2.0043,
      "step": 1770
    },
    {
      "epoch": 1.1328560063643596,
      "grad_norm": 0.6070456504821777,
      "learning_rate": 0.00016282497989815063,
      "loss": 1.9382,
      "step": 1780
    },
    {
      "epoch": 1.1392203659506763,
      "grad_norm": 0.6205413937568665,
      "learning_rate": 0.00016255695523988207,
      "loss": 1.8645,
      "step": 1790
    },
    {
      "epoch": 1.1455847255369929,
      "grad_norm": 0.5668299794197083,
      "learning_rate": 0.00016228893058161352,
      "loss": 1.9233,
      "step": 1800
    },
    {
      "epoch": 1.1455847255369929,
      "eval_loss": 2.057692289352417,
      "eval_runtime": 148.0623,
      "eval_samples_per_second": 4.721,
      "eval_steps_per_second": 0.594,
      "step": 1800
    },
    {
      "epoch": 1.1519490851233094,
      "grad_norm": 0.6869671940803528,
      "learning_rate": 0.00016202090592334496,
      "loss": 1.8915,
      "step": 1810
    },
    {
      "epoch": 1.1583134447096262,
      "grad_norm": 0.5524093508720398,
      "learning_rate": 0.00016175288126507638,
      "loss": 1.9453,
      "step": 1820
    },
    {
      "epoch": 1.1646778042959427,
      "grad_norm": 0.6910571455955505,
      "learning_rate": 0.00016148485660680783,
      "loss": 1.9436,
      "step": 1830
    },
    {
      "epoch": 1.1710421638822592,
      "grad_norm": 0.5992419123649597,
      "learning_rate": 0.00016121683194853927,
      "loss": 1.8873,
      "step": 1840
    },
    {
      "epoch": 1.177406523468576,
      "grad_norm": 0.714258074760437,
      "learning_rate": 0.00016094880729027072,
      "loss": 1.9328,
      "step": 1850
    },
    {
      "epoch": 1.1837708830548925,
      "grad_norm": 0.6538758277893066,
      "learning_rate": 0.00016068078263200216,
      "loss": 1.8535,
      "step": 1860
    },
    {
      "epoch": 1.1901352426412093,
      "grad_norm": 0.5463134050369263,
      "learning_rate": 0.00016041275797373358,
      "loss": 1.929,
      "step": 1870
    },
    {
      "epoch": 1.1964996022275258,
      "grad_norm": 0.5780949592590332,
      "learning_rate": 0.00016014473331546502,
      "loss": 1.8824,
      "step": 1880
    },
    {
      "epoch": 1.2028639618138426,
      "grad_norm": 0.9472821950912476,
      "learning_rate": 0.00015987670865719647,
      "loss": 1.88,
      "step": 1890
    },
    {
      "epoch": 1.2092283214001591,
      "grad_norm": 0.6672549247741699,
      "learning_rate": 0.0001596086839989279,
      "loss": 1.8525,
      "step": 1900
    },
    {
      "epoch": 1.2155926809864757,
      "grad_norm": 0.7280678153038025,
      "learning_rate": 0.00015934065934065933,
      "loss": 1.8843,
      "step": 1910
    },
    {
      "epoch": 1.2219570405727924,
      "grad_norm": 0.52799391746521,
      "learning_rate": 0.0001590726346823908,
      "loss": 1.9316,
      "step": 1920
    },
    {
      "epoch": 1.228321400159109,
      "grad_norm": 0.7355018258094788,
      "learning_rate": 0.00015880461002412225,
      "loss": 1.9443,
      "step": 1930
    },
    {
      "epoch": 1.2346857597454255,
      "grad_norm": 0.6030256748199463,
      "learning_rate": 0.00015853658536585366,
      "loss": 1.8568,
      "step": 1940
    },
    {
      "epoch": 1.2410501193317423,
      "grad_norm": 0.787470281124115,
      "learning_rate": 0.0001582685607075851,
      "loss": 1.9567,
      "step": 1950
    },
    {
      "epoch": 1.2474144789180588,
      "grad_norm": 0.6927269697189331,
      "learning_rate": 0.00015800053604931655,
      "loss": 1.9299,
      "step": 1960
    },
    {
      "epoch": 1.2537788385043755,
      "grad_norm": 0.6013396978378296,
      "learning_rate": 0.000157732511391048,
      "loss": 1.8894,
      "step": 1970
    },
    {
      "epoch": 1.260143198090692,
      "grad_norm": 0.6751870512962341,
      "learning_rate": 0.00015746448673277942,
      "loss": 1.8601,
      "step": 1980
    },
    {
      "epoch": 1.2665075576770088,
      "grad_norm": 0.6631737351417542,
      "learning_rate": 0.00015719646207451086,
      "loss": 1.8824,
      "step": 1990
    },
    {
      "epoch": 1.2728719172633254,
      "grad_norm": 0.5703368782997131,
      "learning_rate": 0.0001569284374162423,
      "loss": 1.9436,
      "step": 2000
    },
    {
      "epoch": 1.2728719172633254,
      "eval_loss": 2.0521976947784424,
      "eval_runtime": 148.0427,
      "eval_samples_per_second": 4.722,
      "eval_steps_per_second": 0.594,
      "step": 2000
    },
    {
      "epoch": 1.279236276849642,
      "grad_norm": 0.6159646511077881,
      "learning_rate": 0.00015666041275797375,
      "loss": 1.9153,
      "step": 2010
    },
    {
      "epoch": 1.2856006364359587,
      "grad_norm": 0.6001470685005188,
      "learning_rate": 0.00015639238809970517,
      "loss": 1.9801,
      "step": 2020
    },
    {
      "epoch": 1.2919649960222752,
      "grad_norm": 0.7141592502593994,
      "learning_rate": 0.0001561243634414366,
      "loss": 1.8325,
      "step": 2030
    },
    {
      "epoch": 1.2983293556085918,
      "grad_norm": 0.6077631115913391,
      "learning_rate": 0.00015585633878316806,
      "loss": 1.8956,
      "step": 2040
    },
    {
      "epoch": 1.3046937151949085,
      "grad_norm": 0.6539301872253418,
      "learning_rate": 0.0001555883141248995,
      "loss": 1.8418,
      "step": 2050
    },
    {
      "epoch": 1.3110580747812253,
      "grad_norm": 0.6179779767990112,
      "learning_rate": 0.00015532028946663092,
      "loss": 1.8691,
      "step": 2060
    },
    {
      "epoch": 1.3174224343675418,
      "grad_norm": 0.6182443499565125,
      "learning_rate": 0.00015505226480836236,
      "loss": 1.9127,
      "step": 2070
    },
    {
      "epoch": 1.3237867939538583,
      "grad_norm": 0.6276934742927551,
      "learning_rate": 0.0001547842401500938,
      "loss": 1.8547,
      "step": 2080
    },
    {
      "epoch": 1.330151153540175,
      "grad_norm": 0.5988945364952087,
      "learning_rate": 0.00015451621549182525,
      "loss": 1.9706,
      "step": 2090
    },
    {
      "epoch": 1.3365155131264916,
      "grad_norm": 0.7017141580581665,
      "learning_rate": 0.0001542481908335567,
      "loss": 1.9418,
      "step": 2100
    },
    {
      "epoch": 1.3428798727128082,
      "grad_norm": 0.6094074249267578,
      "learning_rate": 0.00015398016617528814,
      "loss": 1.9462,
      "step": 2110
    },
    {
      "epoch": 1.349244232299125,
      "grad_norm": 0.7996549010276794,
      "learning_rate": 0.0001537121415170196,
      "loss": 1.8568,
      "step": 2120
    },
    {
      "epoch": 1.3556085918854415,
      "grad_norm": 0.5490034222602844,
      "learning_rate": 0.00015344411685875103,
      "loss": 1.9133,
      "step": 2130
    },
    {
      "epoch": 1.3619729514717582,
      "grad_norm": 0.6175856590270996,
      "learning_rate": 0.00015317609220048245,
      "loss": 1.9301,
      "step": 2140
    },
    {
      "epoch": 1.3683373110580748,
      "grad_norm": 0.6361208558082581,
      "learning_rate": 0.0001529080675422139,
      "loss": 1.8791,
      "step": 2150
    },
    {
      "epoch": 1.3747016706443915,
      "grad_norm": 0.6798582673072815,
      "learning_rate": 0.00015264004288394534,
      "loss": 1.8925,
      "step": 2160
    },
    {
      "epoch": 1.381066030230708,
      "grad_norm": 0.6018432378768921,
      "learning_rate": 0.00015237201822567678,
      "loss": 1.9721,
      "step": 2170
    },
    {
      "epoch": 1.3874303898170246,
      "grad_norm": 0.7017462253570557,
      "learning_rate": 0.0001521039935674082,
      "loss": 2.0351,
      "step": 2180
    },
    {
      "epoch": 1.3937947494033414,
      "grad_norm": 0.6200526356697083,
      "learning_rate": 0.00015183596890913965,
      "loss": 1.8598,
      "step": 2190
    },
    {
      "epoch": 1.400159108989658,
      "grad_norm": 0.6219425201416016,
      "learning_rate": 0.0001515679442508711,
      "loss": 1.9909,
      "step": 2200
    },
    {
      "epoch": 1.400159108989658,
      "eval_loss": 2.0517537593841553,
      "eval_runtime": 148.1365,
      "eval_samples_per_second": 4.719,
      "eval_steps_per_second": 0.594,
      "step": 2200
    },
    {
      "epoch": 1.4065234685759744,
      "grad_norm": 0.5764554738998413,
      "learning_rate": 0.00015129991959260254,
      "loss": 1.8524,
      "step": 2210
    },
    {
      "epoch": 1.4128878281622912,
      "grad_norm": 0.7661691904067993,
      "learning_rate": 0.00015103189493433395,
      "loss": 1.8422,
      "step": 2220
    },
    {
      "epoch": 1.4192521877486077,
      "grad_norm": 0.759437084197998,
      "learning_rate": 0.0001507638702760654,
      "loss": 1.8875,
      "step": 2230
    },
    {
      "epoch": 1.4256165473349245,
      "grad_norm": 0.5272967219352722,
      "learning_rate": 0.00015049584561779684,
      "loss": 1.898,
      "step": 2240
    },
    {
      "epoch": 1.431980906921241,
      "grad_norm": 0.5280800461769104,
      "learning_rate": 0.0001502278209595283,
      "loss": 1.931,
      "step": 2250
    },
    {
      "epoch": 1.4383452665075578,
      "grad_norm": 0.665488064289093,
      "learning_rate": 0.0001499597963012597,
      "loss": 1.9515,
      "step": 2260
    },
    {
      "epoch": 1.4447096260938743,
      "grad_norm": 0.6718887090682983,
      "learning_rate": 0.00014969177164299115,
      "loss": 1.9485,
      "step": 2270
    },
    {
      "epoch": 1.4510739856801909,
      "grad_norm": 0.6323448419570923,
      "learning_rate": 0.00014942374698472262,
      "loss": 1.9096,
      "step": 2280
    },
    {
      "epoch": 1.4574383452665076,
      "grad_norm": 0.6210266351699829,
      "learning_rate": 0.00014915572232645404,
      "loss": 1.9106,
      "step": 2290
    },
    {
      "epoch": 1.4638027048528242,
      "grad_norm": 0.5758326053619385,
      "learning_rate": 0.00014888769766818548,
      "loss": 1.967,
      "step": 2300
    },
    {
      "epoch": 1.4701670644391407,
      "grad_norm": 0.7777416706085205,
      "learning_rate": 0.00014861967300991693,
      "loss": 1.962,
      "step": 2310
    },
    {
      "epoch": 1.4765314240254575,
      "grad_norm": 0.6671023964881897,
      "learning_rate": 0.00014835164835164837,
      "loss": 1.8152,
      "step": 2320
    },
    {
      "epoch": 1.482895783611774,
      "grad_norm": 0.5907175540924072,
      "learning_rate": 0.0001480836236933798,
      "loss": 1.9017,
      "step": 2330
    },
    {
      "epoch": 1.4892601431980907,
      "grad_norm": 0.6267902851104736,
      "learning_rate": 0.00014781559903511124,
      "loss": 1.9008,
      "step": 2340
    },
    {
      "epoch": 1.4956245027844073,
      "grad_norm": 0.5876646041870117,
      "learning_rate": 0.00014754757437684268,
      "loss": 1.885,
      "step": 2350
    },
    {
      "epoch": 1.501988862370724,
      "grad_norm": 0.5355753898620605,
      "learning_rate": 0.00014727954971857412,
      "loss": 1.9485,
      "step": 2360
    },
    {
      "epoch": 1.5083532219570406,
      "grad_norm": 0.6433237791061401,
      "learning_rate": 0.00014701152506030554,
      "loss": 1.9337,
      "step": 2370
    },
    {
      "epoch": 1.5147175815433571,
      "grad_norm": 0.7646932005882263,
      "learning_rate": 0.000146743500402037,
      "loss": 1.8542,
      "step": 2380
    },
    {
      "epoch": 1.5210819411296739,
      "grad_norm": 0.7974744439125061,
      "learning_rate": 0.00014647547574376843,
      "loss": 1.854,
      "step": 2390
    },
    {
      "epoch": 1.5274463007159904,
      "grad_norm": 0.6015125513076782,
      "learning_rate": 0.00014620745108549988,
      "loss": 1.8904,
      "step": 2400
    },
    {
      "epoch": 1.5274463007159904,
      "eval_loss": 2.054455518722534,
      "eval_runtime": 148.1125,
      "eval_samples_per_second": 4.719,
      "eval_steps_per_second": 0.594,
      "step": 2400
    },
    {
      "epoch": 1.533810660302307,
      "grad_norm": 0.7266496419906616,
      "learning_rate": 0.0001459394264272313,
      "loss": 1.8689,
      "step": 2410
    },
    {
      "epoch": 1.5401750198886237,
      "grad_norm": 0.6038923263549805,
      "learning_rate": 0.00014567140176896274,
      "loss": 1.8546,
      "step": 2420
    },
    {
      "epoch": 1.5465393794749405,
      "grad_norm": 0.5508569478988647,
      "learning_rate": 0.00014540337711069418,
      "loss": 1.8518,
      "step": 2430
    },
    {
      "epoch": 1.552903739061257,
      "grad_norm": 0.549602210521698,
      "learning_rate": 0.00014513535245242563,
      "loss": 1.8915,
      "step": 2440
    },
    {
      "epoch": 1.5592680986475735,
      "grad_norm": 0.8779991865158081,
      "learning_rate": 0.00014486732779415705,
      "loss": 2.0529,
      "step": 2450
    },
    {
      "epoch": 1.5656324582338903,
      "grad_norm": 0.7383897304534912,
      "learning_rate": 0.00014459930313588852,
      "loss": 1.8694,
      "step": 2460
    },
    {
      "epoch": 1.5719968178202068,
      "grad_norm": 0.5485044121742249,
      "learning_rate": 0.00014433127847761996,
      "loss": 1.8973,
      "step": 2470
    },
    {
      "epoch": 1.5783611774065234,
      "grad_norm": 0.7989224791526794,
      "learning_rate": 0.0001440632538193514,
      "loss": 1.8195,
      "step": 2480
    },
    {
      "epoch": 1.5847255369928401,
      "grad_norm": 0.5462278723716736,
      "learning_rate": 0.00014379522916108282,
      "loss": 1.9929,
      "step": 2490
    },
    {
      "epoch": 1.5910898965791567,
      "grad_norm": 0.603995144367218,
      "learning_rate": 0.00014352720450281427,
      "loss": 1.9432,
      "step": 2500
    },
    {
      "epoch": 1.5974542561654732,
      "grad_norm": 0.6383550763130188,
      "learning_rate": 0.00014325917984454571,
      "loss": 1.8109,
      "step": 2510
    },
    {
      "epoch": 1.60381861575179,
      "grad_norm": 0.5217467546463013,
      "learning_rate": 0.00014299115518627716,
      "loss": 1.8573,
      "step": 2520
    },
    {
      "epoch": 1.6101829753381067,
      "grad_norm": 0.7727627158164978,
      "learning_rate": 0.00014272313052800858,
      "loss": 1.9016,
      "step": 2530
    },
    {
      "epoch": 1.6165473349244233,
      "grad_norm": 0.5519369840621948,
      "learning_rate": 0.00014245510586974002,
      "loss": 1.921,
      "step": 2540
    },
    {
      "epoch": 1.6229116945107398,
      "grad_norm": 0.7725760340690613,
      "learning_rate": 0.00014218708121147147,
      "loss": 1.866,
      "step": 2550
    },
    {
      "epoch": 1.6292760540970566,
      "grad_norm": 0.7450507283210754,
      "learning_rate": 0.0001419190565532029,
      "loss": 1.8963,
      "step": 2560
    },
    {
      "epoch": 1.635640413683373,
      "grad_norm": 0.7180888652801514,
      "learning_rate": 0.00014165103189493433,
      "loss": 1.8306,
      "step": 2570
    },
    {
      "epoch": 1.6420047732696896,
      "grad_norm": 0.7086076140403748,
      "learning_rate": 0.00014138300723666577,
      "loss": 1.9151,
      "step": 2580
    },
    {
      "epoch": 1.6483691328560064,
      "grad_norm": 0.8466945290565491,
      "learning_rate": 0.00014111498257839722,
      "loss": 1.8863,
      "step": 2590
    },
    {
      "epoch": 1.6547334924423232,
      "grad_norm": 0.6244062185287476,
      "learning_rate": 0.00014084695792012866,
      "loss": 1.9209,
      "step": 2600
    },
    {
      "epoch": 1.6547334924423232,
      "eval_loss": 2.0507917404174805,
      "eval_runtime": 148.0182,
      "eval_samples_per_second": 4.722,
      "eval_steps_per_second": 0.595,
      "step": 2600
    },
    {
      "epoch": 1.6610978520286395,
      "grad_norm": 0.6196523904800415,
      "learning_rate": 0.00014057893326186008,
      "loss": 1.9132,
      "step": 2610
    },
    {
      "epoch": 1.6674622116149562,
      "grad_norm": 0.6968696117401123,
      "learning_rate": 0.00014031090860359152,
      "loss": 1.7427,
      "step": 2620
    },
    {
      "epoch": 1.673826571201273,
      "grad_norm": 0.6390512585639954,
      "learning_rate": 0.00014004288394532297,
      "loss": 1.7986,
      "step": 2630
    },
    {
      "epoch": 1.6801909307875895,
      "grad_norm": 0.5822598338127136,
      "learning_rate": 0.00013977485928705441,
      "loss": 1.9765,
      "step": 2640
    },
    {
      "epoch": 1.686555290373906,
      "grad_norm": 0.49704214930534363,
      "learning_rate": 0.00013950683462878586,
      "loss": 1.8206,
      "step": 2650
    },
    {
      "epoch": 1.6929196499602228,
      "grad_norm": 0.7694344520568848,
      "learning_rate": 0.0001392388099705173,
      "loss": 1.8348,
      "step": 2660
    },
    {
      "epoch": 1.6992840095465394,
      "grad_norm": 0.8217739462852478,
      "learning_rate": 0.00013897078531224875,
      "loss": 1.9064,
      "step": 2670
    },
    {
      "epoch": 1.705648369132856,
      "grad_norm": 0.5390772819519043,
      "learning_rate": 0.00013870276065398017,
      "loss": 1.8044,
      "step": 2680
    },
    {
      "epoch": 1.7120127287191726,
      "grad_norm": 0.5876647233963013,
      "learning_rate": 0.0001384347359957116,
      "loss": 1.8014,
      "step": 2690
    },
    {
      "epoch": 1.7183770883054894,
      "grad_norm": 0.589756429195404,
      "learning_rate": 0.00013816671133744306,
      "loss": 1.7679,
      "step": 2700
    },
    {
      "epoch": 1.7247414478918057,
      "grad_norm": 0.739224374294281,
      "learning_rate": 0.0001378986866791745,
      "loss": 1.972,
      "step": 2710
    },
    {
      "epoch": 1.7311058074781225,
      "grad_norm": 0.5497722029685974,
      "learning_rate": 0.00013763066202090594,
      "loss": 1.8173,
      "step": 2720
    },
    {
      "epoch": 1.7374701670644392,
      "grad_norm": 0.6628929972648621,
      "learning_rate": 0.00013736263736263736,
      "loss": 1.915,
      "step": 2730
    },
    {
      "epoch": 1.7438345266507558,
      "grad_norm": 0.7010061144828796,
      "learning_rate": 0.0001370946127043688,
      "loss": 1.9157,
      "step": 2740
    },
    {
      "epoch": 1.7501988862370723,
      "grad_norm": 0.6964478492736816,
      "learning_rate": 0.00013682658804610025,
      "loss": 2.0402,
      "step": 2750
    },
    {
      "epoch": 1.756563245823389,
      "grad_norm": 0.685426652431488,
      "learning_rate": 0.0001365585633878317,
      "loss": 2.036,
      "step": 2760
    },
    {
      "epoch": 1.7629276054097056,
      "grad_norm": 0.6728571653366089,
      "learning_rate": 0.00013629053872956311,
      "loss": 1.8235,
      "step": 2770
    },
    {
      "epoch": 1.7692919649960221,
      "grad_norm": 0.8188900351524353,
      "learning_rate": 0.00013602251407129456,
      "loss": 1.9576,
      "step": 2780
    },
    {
      "epoch": 1.775656324582339,
      "grad_norm": 0.5291470885276794,
      "learning_rate": 0.000135754489413026,
      "loss": 1.8303,
      "step": 2790
    },
    {
      "epoch": 1.7820206841686557,
      "grad_norm": 0.7289562225341797,
      "learning_rate": 0.00013548646475475745,
      "loss": 1.9015,
      "step": 2800
    },
    {
      "epoch": 1.7820206841686557,
      "eval_loss": 2.045496702194214,
      "eval_runtime": 147.9819,
      "eval_samples_per_second": 4.724,
      "eval_steps_per_second": 0.595,
      "step": 2800
    },
    {
      "epoch": 1.7883850437549722,
      "grad_norm": 0.6162169575691223,
      "learning_rate": 0.00013521844009648887,
      "loss": 1.9472,
      "step": 2810
    },
    {
      "epoch": 1.7947494033412887,
      "grad_norm": 0.6996170282363892,
      "learning_rate": 0.0001349504154382203,
      "loss": 1.8705,
      "step": 2820
    },
    {
      "epoch": 1.8011137629276055,
      "grad_norm": 0.6087537407875061,
      "learning_rate": 0.00013468239077995178,
      "loss": 1.8447,
      "step": 2830
    },
    {
      "epoch": 1.807478122513922,
      "grad_norm": 0.6371230483055115,
      "learning_rate": 0.0001344143661216832,
      "loss": 1.8566,
      "step": 2840
    },
    {
      "epoch": 1.8138424821002386,
      "grad_norm": 0.6496568918228149,
      "learning_rate": 0.00013414634146341464,
      "loss": 1.8461,
      "step": 2850
    },
    {
      "epoch": 1.8202068416865553,
      "grad_norm": 0.6229597926139832,
      "learning_rate": 0.0001338783168051461,
      "loss": 2.0167,
      "step": 2860
    },
    {
      "epoch": 1.8265712012728719,
      "grad_norm": 0.6042510867118835,
      "learning_rate": 0.00013361029214687753,
      "loss": 1.8205,
      "step": 2870
    },
    {
      "epoch": 1.8329355608591884,
      "grad_norm": 0.5714908838272095,
      "learning_rate": 0.00013334226748860895,
      "loss": 1.8998,
      "step": 2880
    },
    {
      "epoch": 1.8392999204455052,
      "grad_norm": 0.8447912335395813,
      "learning_rate": 0.0001330742428303404,
      "loss": 1.9092,
      "step": 2890
    },
    {
      "epoch": 1.845664280031822,
      "grad_norm": 0.8293684720993042,
      "learning_rate": 0.00013280621817207184,
      "loss": 1.8532,
      "step": 2900
    },
    {
      "epoch": 1.8520286396181385,
      "grad_norm": 0.6097157001495361,
      "learning_rate": 0.00013253819351380329,
      "loss": 1.9465,
      "step": 2910
    },
    {
      "epoch": 1.858392999204455,
      "grad_norm": 0.7449460029602051,
      "learning_rate": 0.0001322701688555347,
      "loss": 1.836,
      "step": 2920
    },
    {
      "epoch": 1.8647573587907718,
      "grad_norm": 0.7327731251716614,
      "learning_rate": 0.00013200214419726615,
      "loss": 1.9115,
      "step": 2930
    },
    {
      "epoch": 1.8711217183770883,
      "grad_norm": 0.7340664267539978,
      "learning_rate": 0.0001317341195389976,
      "loss": 1.8793,
      "step": 2940
    },
    {
      "epoch": 1.8774860779634048,
      "grad_norm": 0.6977156400680542,
      "learning_rate": 0.00013146609488072904,
      "loss": 1.9093,
      "step": 2950
    },
    {
      "epoch": 1.8838504375497216,
      "grad_norm": 0.6629152894020081,
      "learning_rate": 0.00013119807022246046,
      "loss": 1.895,
      "step": 2960
    },
    {
      "epoch": 1.8902147971360383,
      "grad_norm": 0.5935922265052795,
      "learning_rate": 0.0001309300455641919,
      "loss": 1.887,
      "step": 2970
    },
    {
      "epoch": 1.8965791567223547,
      "grad_norm": 0.6553559303283691,
      "learning_rate": 0.00013066202090592334,
      "loss": 1.8077,
      "step": 2980
    },
    {
      "epoch": 1.9029435163086714,
      "grad_norm": 0.6172764301300049,
      "learning_rate": 0.0001303939962476548,
      "loss": 1.8738,
      "step": 2990
    },
    {
      "epoch": 1.9093078758949882,
      "grad_norm": 0.5974670052528381,
      "learning_rate": 0.0001301259715893862,
      "loss": 1.9146,
      "step": 3000
    },
    {
      "epoch": 1.9093078758949882,
      "eval_loss": 2.047985076904297,
      "eval_runtime": 147.8692,
      "eval_samples_per_second": 4.727,
      "eval_steps_per_second": 0.595,
      "step": 3000
    },
    {
      "epoch": 1.9156722354813047,
      "grad_norm": 0.7319176197052002,
      "learning_rate": 0.00012985794693111768,
      "loss": 1.8105,
      "step": 3010
    },
    {
      "epoch": 1.9220365950676213,
      "grad_norm": 0.7099266648292542,
      "learning_rate": 0.00012958992227284912,
      "loss": 1.8869,
      "step": 3020
    },
    {
      "epoch": 1.928400954653938,
      "grad_norm": 0.5901165008544922,
      "learning_rate": 0.00012932189761458057,
      "loss": 1.7877,
      "step": 3030
    },
    {
      "epoch": 1.9347653142402546,
      "grad_norm": 0.6069875359535217,
      "learning_rate": 0.00012905387295631199,
      "loss": 1.9792,
      "step": 3040
    },
    {
      "epoch": 1.941129673826571,
      "grad_norm": 0.7304983735084534,
      "learning_rate": 0.00012878584829804343,
      "loss": 1.7854,
      "step": 3050
    },
    {
      "epoch": 1.9474940334128878,
      "grad_norm": 0.5927680134773254,
      "learning_rate": 0.00012851782363977488,
      "loss": 1.972,
      "step": 3060
    },
    {
      "epoch": 1.9538583929992046,
      "grad_norm": 0.6414054036140442,
      "learning_rate": 0.00012824979898150632,
      "loss": 1.879,
      "step": 3070
    },
    {
      "epoch": 1.960222752585521,
      "grad_norm": 0.7153280973434448,
      "learning_rate": 0.00012798177432323774,
      "loss": 1.8272,
      "step": 3080
    },
    {
      "epoch": 1.9665871121718377,
      "grad_norm": 0.6605225205421448,
      "learning_rate": 0.00012771374966496918,
      "loss": 1.9058,
      "step": 3090
    },
    {
      "epoch": 1.9729514717581544,
      "grad_norm": 0.6645078063011169,
      "learning_rate": 0.00012744572500670063,
      "loss": 1.7676,
      "step": 3100
    },
    {
      "epoch": 1.979315831344471,
      "grad_norm": 0.6509796977043152,
      "learning_rate": 0.00012717770034843207,
      "loss": 1.8564,
      "step": 3110
    },
    {
      "epoch": 1.9856801909307875,
      "grad_norm": 0.6673306226730347,
      "learning_rate": 0.0001269096756901635,
      "loss": 1.8739,
      "step": 3120
    },
    {
      "epoch": 1.9920445505171043,
      "grad_norm": 0.6851851940155029,
      "learning_rate": 0.00012664165103189493,
      "loss": 2.0304,
      "step": 3130
    },
    {
      "epoch": 1.9984089101034208,
      "grad_norm": 0.5546568036079407,
      "learning_rate": 0.00012637362637362638,
      "loss": 1.9209,
      "step": 3140
    },
    {
      "epoch": 2.0047732696897373,
      "grad_norm": 0.6404918432235718,
      "learning_rate": 0.00012610560171535782,
      "loss": 2.0171,
      "step": 3150
    },
    {
      "epoch": 2.011137629276054,
      "grad_norm": 0.6881417632102966,
      "learning_rate": 0.00012583757705708924,
      "loss": 1.8515,
      "step": 3160
    },
    {
      "epoch": 2.017501988862371,
      "grad_norm": 0.8027366995811462,
      "learning_rate": 0.00012556955239882069,
      "loss": 1.7626,
      "step": 3170
    },
    {
      "epoch": 2.023866348448687,
      "grad_norm": 0.726440966129303,
      "learning_rate": 0.00012530152774055213,
      "loss": 1.8028,
      "step": 3180
    },
    {
      "epoch": 2.030230708035004,
      "grad_norm": 0.611445426940918,
      "learning_rate": 0.00012503350308228358,
      "loss": 1.7586,
      "step": 3190
    },
    {
      "epoch": 2.0365950676213207,
      "grad_norm": 0.6764002442359924,
      "learning_rate": 0.00012476547842401502,
      "loss": 1.7897,
      "step": 3200
    },
    {
      "epoch": 2.0365950676213207,
      "eval_loss": 2.0565638542175293,
      "eval_runtime": 148.0117,
      "eval_samples_per_second": 4.723,
      "eval_steps_per_second": 0.595,
      "step": 3200
    },
    {
      "epoch": 2.042959427207637,
      "grad_norm": 0.8270775675773621,
      "learning_rate": 0.00012449745376574646,
      "loss": 1.9255,
      "step": 3210
    },
    {
      "epoch": 2.0493237867939538,
      "grad_norm": 0.6619228720664978,
      "learning_rate": 0.0001242294291074779,
      "loss": 1.8346,
      "step": 3220
    },
    {
      "epoch": 2.0556881463802705,
      "grad_norm": 0.6221789717674255,
      "learning_rate": 0.00012396140444920933,
      "loss": 1.791,
      "step": 3230
    },
    {
      "epoch": 2.0620525059665873,
      "grad_norm": 0.6324142217636108,
      "learning_rate": 0.00012369337979094077,
      "loss": 1.7853,
      "step": 3240
    },
    {
      "epoch": 2.0684168655529036,
      "grad_norm": 0.7610169649124146,
      "learning_rate": 0.00012342535513267222,
      "loss": 1.8932,
      "step": 3250
    },
    {
      "epoch": 2.0747812251392204,
      "grad_norm": 0.6447398662567139,
      "learning_rate": 0.00012315733047440366,
      "loss": 1.7738,
      "step": 3260
    },
    {
      "epoch": 2.081145584725537,
      "grad_norm": 0.6424939632415771,
      "learning_rate": 0.00012288930581613508,
      "loss": 1.6961,
      "step": 3270
    },
    {
      "epoch": 2.0875099443118534,
      "grad_norm": 0.5583698153495789,
      "learning_rate": 0.00012262128115786652,
      "loss": 1.7786,
      "step": 3280
    },
    {
      "epoch": 2.09387430389817,
      "grad_norm": 0.7817251086235046,
      "learning_rate": 0.00012235325649959797,
      "loss": 1.8776,
      "step": 3290
    },
    {
      "epoch": 2.100238663484487,
      "grad_norm": 0.6763550043106079,
      "learning_rate": 0.0001220852318413294,
      "loss": 1.8341,
      "step": 3300
    },
    {
      "epoch": 2.1066030230708037,
      "grad_norm": 0.6258336901664734,
      "learning_rate": 0.00012181720718306084,
      "loss": 1.8153,
      "step": 3310
    },
    {
      "epoch": 2.11296738265712,
      "grad_norm": 0.8618139624595642,
      "learning_rate": 0.00012154918252479229,
      "loss": 1.8436,
      "step": 3320
    },
    {
      "epoch": 2.119331742243437,
      "grad_norm": 0.6598134636878967,
      "learning_rate": 0.00012128115786652372,
      "loss": 1.878,
      "step": 3330
    },
    {
      "epoch": 2.1256961018297535,
      "grad_norm": 0.7356264591217041,
      "learning_rate": 0.00012101313320825516,
      "loss": 1.8894,
      "step": 3340
    },
    {
      "epoch": 2.13206046141607,
      "grad_norm": 0.6766697764396667,
      "learning_rate": 0.0001207451085499866,
      "loss": 1.7276,
      "step": 3350
    },
    {
      "epoch": 2.1384248210023866,
      "grad_norm": 0.6238960027694702,
      "learning_rate": 0.00012047708389171804,
      "loss": 1.7496,
      "step": 3360
    },
    {
      "epoch": 2.1447891805887034,
      "grad_norm": 0.8109233379364014,
      "learning_rate": 0.00012020905923344947,
      "loss": 1.8744,
      "step": 3370
    },
    {
      "epoch": 2.1511535401750197,
      "grad_norm": 0.7404519319534302,
      "learning_rate": 0.00011994103457518093,
      "loss": 1.7303,
      "step": 3380
    },
    {
      "epoch": 2.1575178997613365,
      "grad_norm": 0.5994895696640015,
      "learning_rate": 0.00011967300991691237,
      "loss": 1.8413,
      "step": 3390
    },
    {
      "epoch": 2.163882259347653,
      "grad_norm": 0.6245433688163757,
      "learning_rate": 0.0001194049852586438,
      "loss": 1.7872,
      "step": 3400
    },
    {
      "epoch": 2.163882259347653,
      "eval_loss": 2.05869197845459,
      "eval_runtime": 147.9471,
      "eval_samples_per_second": 4.725,
      "eval_steps_per_second": 0.595,
      "step": 3400
    },
    {
      "epoch": 2.17024661893397,
      "grad_norm": 0.8221827745437622,
      "learning_rate": 0.00011913696060037525,
      "loss": 1.7769,
      "step": 3410
    },
    {
      "epoch": 2.1766109785202863,
      "grad_norm": 0.862419605255127,
      "learning_rate": 0.00011886893594210668,
      "loss": 1.8865,
      "step": 3420
    },
    {
      "epoch": 2.182975338106603,
      "grad_norm": 0.6631574630737305,
      "learning_rate": 0.00011860091128383813,
      "loss": 1.7682,
      "step": 3430
    },
    {
      "epoch": 2.18933969769292,
      "grad_norm": 0.7566444873809814,
      "learning_rate": 0.00011833288662556956,
      "loss": 1.9222,
      "step": 3440
    },
    {
      "epoch": 2.195704057279236,
      "grad_norm": 0.8155741095542908,
      "learning_rate": 0.000118064861967301,
      "loss": 1.7971,
      "step": 3450
    },
    {
      "epoch": 2.202068416865553,
      "grad_norm": 0.6468359231948853,
      "learning_rate": 0.00011779683730903243,
      "loss": 1.7344,
      "step": 3460
    },
    {
      "epoch": 2.2084327764518696,
      "grad_norm": 0.6650047302246094,
      "learning_rate": 0.00011752881265076388,
      "loss": 1.7342,
      "step": 3470
    },
    {
      "epoch": 2.214797136038186,
      "grad_norm": 0.5917614102363586,
      "learning_rate": 0.00011726078799249531,
      "loss": 1.8659,
      "step": 3480
    },
    {
      "epoch": 2.2211614956245027,
      "grad_norm": 0.6257355809211731,
      "learning_rate": 0.00011699276333422675,
      "loss": 1.7682,
      "step": 3490
    },
    {
      "epoch": 2.2275258552108195,
      "grad_norm": 0.6750785708427429,
      "learning_rate": 0.00011672473867595819,
      "loss": 1.8743,
      "step": 3500
    },
    {
      "epoch": 2.2338902147971362,
      "grad_norm": 0.7375034093856812,
      "learning_rate": 0.00011645671401768963,
      "loss": 1.7843,
      "step": 3510
    },
    {
      "epoch": 2.2402545743834525,
      "grad_norm": 0.7401970624923706,
      "learning_rate": 0.00011618868935942106,
      "loss": 1.8192,
      "step": 3520
    },
    {
      "epoch": 2.2466189339697693,
      "grad_norm": 0.8011008501052856,
      "learning_rate": 0.0001159206647011525,
      "loss": 1.9119,
      "step": 3530
    },
    {
      "epoch": 2.252983293556086,
      "grad_norm": 0.6912602186203003,
      "learning_rate": 0.00011565264004288394,
      "loss": 1.8436,
      "step": 3540
    },
    {
      "epoch": 2.2593476531424024,
      "grad_norm": 0.5747859477996826,
      "learning_rate": 0.00011538461538461538,
      "loss": 1.8152,
      "step": 3550
    },
    {
      "epoch": 2.265712012728719,
      "grad_norm": 0.9186633825302124,
      "learning_rate": 0.00011511659072634684,
      "loss": 1.8332,
      "step": 3560
    },
    {
      "epoch": 2.272076372315036,
      "grad_norm": 0.7492991089820862,
      "learning_rate": 0.00011484856606807828,
      "loss": 1.8768,
      "step": 3570
    },
    {
      "epoch": 2.2784407319013527,
      "grad_norm": 0.660006046295166,
      "learning_rate": 0.00011458054140980972,
      "loss": 1.7055,
      "step": 3580
    },
    {
      "epoch": 2.284805091487669,
      "grad_norm": 0.7960358262062073,
      "learning_rate": 0.00011431251675154116,
      "loss": 1.8316,
      "step": 3590
    },
    {
      "epoch": 2.2911694510739857,
      "grad_norm": 0.6906083226203918,
      "learning_rate": 0.00011404449209327259,
      "loss": 1.7921,
      "step": 3600
    },
    {
      "epoch": 2.2911694510739857,
      "eval_loss": 2.0558583736419678,
      "eval_runtime": 147.7986,
      "eval_samples_per_second": 4.729,
      "eval_steps_per_second": 0.595,
      "step": 3600
    },
    {
      "epoch": 2.2975338106603025,
      "grad_norm": 0.6791744828224182,
      "learning_rate": 0.00011377646743500404,
      "loss": 1.769,
      "step": 3610
    },
    {
      "epoch": 2.303898170246619,
      "grad_norm": 0.8549902439117432,
      "learning_rate": 0.00011350844277673547,
      "loss": 1.729,
      "step": 3620
    },
    {
      "epoch": 2.3102625298329356,
      "grad_norm": 0.6165910363197327,
      "learning_rate": 0.00011324041811846691,
      "loss": 1.7755,
      "step": 3630
    },
    {
      "epoch": 2.3166268894192523,
      "grad_norm": 0.7031725645065308,
      "learning_rate": 0.00011297239346019834,
      "loss": 1.7924,
      "step": 3640
    },
    {
      "epoch": 2.3229912490055686,
      "grad_norm": 0.5853118300437927,
      "learning_rate": 0.00011270436880192979,
      "loss": 1.7719,
      "step": 3650
    },
    {
      "epoch": 2.3293556085918854,
      "grad_norm": 0.8324174284934998,
      "learning_rate": 0.00011243634414366122,
      "loss": 1.8928,
      "step": 3660
    },
    {
      "epoch": 2.335719968178202,
      "grad_norm": 0.6580143570899963,
      "learning_rate": 0.00011216831948539266,
      "loss": 1.9279,
      "step": 3670
    },
    {
      "epoch": 2.3420843277645185,
      "grad_norm": 0.6703597903251648,
      "learning_rate": 0.0001119002948271241,
      "loss": 1.8645,
      "step": 3680
    },
    {
      "epoch": 2.3484486873508352,
      "grad_norm": 0.8231183886528015,
      "learning_rate": 0.00011163227016885554,
      "loss": 1.6857,
      "step": 3690
    },
    {
      "epoch": 2.354813046937152,
      "grad_norm": 0.8292109370231628,
      "learning_rate": 0.00011136424551058697,
      "loss": 1.8932,
      "step": 3700
    },
    {
      "epoch": 2.3611774065234687,
      "grad_norm": 0.7148052453994751,
      "learning_rate": 0.00011109622085231842,
      "loss": 1.7875,
      "step": 3710
    },
    {
      "epoch": 2.367541766109785,
      "grad_norm": 0.6525492668151855,
      "learning_rate": 0.00011082819619404985,
      "loss": 1.7948,
      "step": 3720
    },
    {
      "epoch": 2.373906125696102,
      "grad_norm": 0.6449699401855469,
      "learning_rate": 0.00011056017153578129,
      "loss": 1.7572,
      "step": 3730
    },
    {
      "epoch": 2.3802704852824186,
      "grad_norm": 0.5588886141777039,
      "learning_rate": 0.00011029214687751275,
      "loss": 1.8277,
      "step": 3740
    },
    {
      "epoch": 2.386634844868735,
      "grad_norm": 0.8357835412025452,
      "learning_rate": 0.00011002412221924418,
      "loss": 1.831,
      "step": 3750
    },
    {
      "epoch": 2.3929992044550517,
      "grad_norm": 0.7312510013580322,
      "learning_rate": 0.00010975609756097563,
      "loss": 1.7222,
      "step": 3760
    },
    {
      "epoch": 2.3993635640413684,
      "grad_norm": 0.8591846227645874,
      "learning_rate": 0.00010948807290270706,
      "loss": 1.8855,
      "step": 3770
    },
    {
      "epoch": 2.405727923627685,
      "grad_norm": 0.6565876007080078,
      "learning_rate": 0.0001092200482444385,
      "loss": 1.7867,
      "step": 3780
    },
    {
      "epoch": 2.4120922832140015,
      "grad_norm": 0.6952947974205017,
      "learning_rate": 0.00010895202358616993,
      "loss": 1.8219,
      "step": 3790
    },
    {
      "epoch": 2.4184566428003182,
      "grad_norm": 0.7004457712173462,
      "learning_rate": 0.00010868399892790138,
      "loss": 1.9035,
      "step": 3800
    },
    {
      "epoch": 2.4184566428003182,
      "eval_loss": 2.05997371673584,
      "eval_runtime": 147.9844,
      "eval_samples_per_second": 4.723,
      "eval_steps_per_second": 0.595,
      "step": 3800
    },
    {
      "epoch": 2.424821002386635,
      "grad_norm": 0.6613615155220032,
      "learning_rate": 0.00010841597426963281,
      "loss": 1.8711,
      "step": 3810
    },
    {
      "epoch": 2.4311853619729513,
      "grad_norm": 0.6908266544342041,
      "learning_rate": 0.00010814794961136425,
      "loss": 1.8589,
      "step": 3820
    },
    {
      "epoch": 2.437549721559268,
      "grad_norm": 0.7993584871292114,
      "learning_rate": 0.00010787992495309568,
      "loss": 1.7934,
      "step": 3830
    },
    {
      "epoch": 2.443914081145585,
      "grad_norm": 0.725280225276947,
      "learning_rate": 0.00010761190029482713,
      "loss": 1.8866,
      "step": 3840
    },
    {
      "epoch": 2.4502784407319016,
      "grad_norm": 0.7674907445907593,
      "learning_rate": 0.00010734387563655856,
      "loss": 1.8783,
      "step": 3850
    },
    {
      "epoch": 2.456642800318218,
      "grad_norm": 0.7068597078323364,
      "learning_rate": 0.00010707585097829,
      "loss": 1.8357,
      "step": 3860
    },
    {
      "epoch": 2.4630071599045347,
      "grad_norm": 0.8859842419624329,
      "learning_rate": 0.00010680782632002144,
      "loss": 1.7843,
      "step": 3870
    },
    {
      "epoch": 2.469371519490851,
      "grad_norm": 0.7624830007553101,
      "learning_rate": 0.00010653980166175288,
      "loss": 1.7513,
      "step": 3880
    },
    {
      "epoch": 2.4757358790771677,
      "grad_norm": 0.7174131274223328,
      "learning_rate": 0.00010627177700348431,
      "loss": 1.9048,
      "step": 3890
    },
    {
      "epoch": 2.4821002386634845,
      "grad_norm": 0.7588567137718201,
      "learning_rate": 0.00010600375234521576,
      "loss": 1.8532,
      "step": 3900
    },
    {
      "epoch": 2.4884645982498013,
      "grad_norm": 0.6902045607566833,
      "learning_rate": 0.00010573572768694719,
      "loss": 1.8298,
      "step": 3910
    },
    {
      "epoch": 2.4948289578361176,
      "grad_norm": 0.6607901453971863,
      "learning_rate": 0.00010546770302867863,
      "loss": 1.8386,
      "step": 3920
    },
    {
      "epoch": 2.5011933174224343,
      "grad_norm": 0.7837931513786316,
      "learning_rate": 0.00010519967837041009,
      "loss": 1.7947,
      "step": 3930
    },
    {
      "epoch": 2.507557677008751,
      "grad_norm": 0.7979212403297424,
      "learning_rate": 0.00010493165371214154,
      "loss": 1.7364,
      "step": 3940
    },
    {
      "epoch": 2.5139220365950674,
      "grad_norm": 0.7752086520195007,
      "learning_rate": 0.00010466362905387297,
      "loss": 1.8507,
      "step": 3950
    },
    {
      "epoch": 2.520286396181384,
      "grad_norm": 0.6941630244255066,
      "learning_rate": 0.00010439560439560441,
      "loss": 1.7283,
      "step": 3960
    },
    {
      "epoch": 2.526650755767701,
      "grad_norm": 0.8144738078117371,
      "learning_rate": 0.00010412757973733584,
      "loss": 1.8516,
      "step": 3970
    },
    {
      "epoch": 2.5330151153540177,
      "grad_norm": 0.7591050267219543,
      "learning_rate": 0.00010385955507906729,
      "loss": 1.9052,
      "step": 3980
    },
    {
      "epoch": 2.539379474940334,
      "grad_norm": 0.7796510457992554,
      "learning_rate": 0.00010359153042079872,
      "loss": 1.7971,
      "step": 3990
    },
    {
      "epoch": 2.5457438345266508,
      "grad_norm": 0.6558085083961487,
      "learning_rate": 0.00010332350576253016,
      "loss": 1.8359,
      "step": 4000
    },
    {
      "epoch": 2.5457438345266508,
      "eval_loss": 2.056201457977295,
      "eval_runtime": 148.217,
      "eval_samples_per_second": 4.716,
      "eval_steps_per_second": 0.594,
      "step": 4000
    },
    {
      "epoch": 2.5521081941129675,
      "grad_norm": 0.7709584832191467,
      "learning_rate": 0.0001030554811042616,
      "loss": 1.7143,
      "step": 4010
    },
    {
      "epoch": 2.558472553699284,
      "grad_norm": 0.7411655187606812,
      "learning_rate": 0.00010278745644599304,
      "loss": 1.7945,
      "step": 4020
    },
    {
      "epoch": 2.5648369132856006,
      "grad_norm": 0.7506970763206482,
      "learning_rate": 0.00010251943178772447,
      "loss": 1.819,
      "step": 4030
    },
    {
      "epoch": 2.5712012728719174,
      "grad_norm": 0.7982520461082458,
      "learning_rate": 0.00010225140712945592,
      "loss": 1.828,
      "step": 4040
    },
    {
      "epoch": 2.577565632458234,
      "grad_norm": 0.6538260579109192,
      "learning_rate": 0.00010198338247118735,
      "loss": 1.7595,
      "step": 4050
    },
    {
      "epoch": 2.5839299920445504,
      "grad_norm": 0.6646845936775208,
      "learning_rate": 0.00010171535781291879,
      "loss": 1.842,
      "step": 4060
    },
    {
      "epoch": 2.590294351630867,
      "grad_norm": 0.8758952617645264,
      "learning_rate": 0.00010144733315465022,
      "loss": 1.9484,
      "step": 4070
    },
    {
      "epoch": 2.5966587112171835,
      "grad_norm": 0.822898268699646,
      "learning_rate": 0.00010117930849638167,
      "loss": 1.8102,
      "step": 4080
    },
    {
      "epoch": 2.6030230708035003,
      "grad_norm": 0.8402432203292847,
      "learning_rate": 0.0001009112838381131,
      "loss": 1.8168,
      "step": 4090
    },
    {
      "epoch": 2.609387430389817,
      "grad_norm": 0.6236563324928284,
      "learning_rate": 0.00010064325917984454,
      "loss": 1.772,
      "step": 4100
    },
    {
      "epoch": 2.615751789976134,
      "grad_norm": 0.6854003071784973,
      "learning_rate": 0.000100375234521576,
      "loss": 1.9119,
      "step": 4110
    },
    {
      "epoch": 2.6221161495624505,
      "grad_norm": 0.674572229385376,
      "learning_rate": 0.00010010720986330743,
      "loss": 1.8862,
      "step": 4120
    },
    {
      "epoch": 2.628480509148767,
      "grad_norm": 0.6416204571723938,
      "learning_rate": 9.983918520503886e-05,
      "loss": 1.8378,
      "step": 4130
    },
    {
      "epoch": 2.6348448687350836,
      "grad_norm": 0.8363381624221802,
      "learning_rate": 9.957116054677031e-05,
      "loss": 1.8473,
      "step": 4140
    },
    {
      "epoch": 2.6412092283214,
      "grad_norm": 0.7034580707550049,
      "learning_rate": 9.930313588850174e-05,
      "loss": 1.8142,
      "step": 4150
    },
    {
      "epoch": 2.6475735879077167,
      "grad_norm": 0.7337253093719482,
      "learning_rate": 9.903511123023318e-05,
      "loss": 1.7526,
      "step": 4160
    },
    {
      "epoch": 2.6539379474940334,
      "grad_norm": 0.9074569940567017,
      "learning_rate": 9.876708657196463e-05,
      "loss": 1.825,
      "step": 4170
    },
    {
      "epoch": 2.66030230708035,
      "grad_norm": 0.8666559457778931,
      "learning_rate": 9.849906191369607e-05,
      "loss": 1.8381,
      "step": 4180
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.7919233441352844,
      "learning_rate": 9.82310372554275e-05,
      "loss": 1.8287,
      "step": 4190
    },
    {
      "epoch": 2.6730310262529833,
      "grad_norm": 0.7408560514450073,
      "learning_rate": 9.796301259715895e-05,
      "loss": 1.7817,
      "step": 4200
    },
    {
      "epoch": 2.6730310262529833,
      "eval_loss": 2.0555193424224854,
      "eval_runtime": 147.8764,
      "eval_samples_per_second": 4.727,
      "eval_steps_per_second": 0.595,
      "step": 4200
    },
    {
      "epoch": 2.6793953858393,
      "grad_norm": 0.6617708206176758,
      "learning_rate": 9.769498793889038e-05,
      "loss": 1.8383,
      "step": 4210
    },
    {
      "epoch": 2.6857597454256164,
      "grad_norm": 0.7592277526855469,
      "learning_rate": 9.742696328062183e-05,
      "loss": 1.9011,
      "step": 4220
    },
    {
      "epoch": 2.692124105011933,
      "grad_norm": 0.7099108099937439,
      "learning_rate": 9.715893862235326e-05,
      "loss": 1.7806,
      "step": 4230
    },
    {
      "epoch": 2.69848846459825,
      "grad_norm": 0.6165810823440552,
      "learning_rate": 9.68909139640847e-05,
      "loss": 1.7932,
      "step": 4240
    },
    {
      "epoch": 2.7048528241845666,
      "grad_norm": 0.7824639678001404,
      "learning_rate": 9.662288930581615e-05,
      "loss": 1.8129,
      "step": 4250
    },
    {
      "epoch": 2.711217183770883,
      "grad_norm": 0.7432408332824707,
      "learning_rate": 9.635486464754758e-05,
      "loss": 1.7458,
      "step": 4260
    },
    {
      "epoch": 2.7175815433571997,
      "grad_norm": 0.6647706031799316,
      "learning_rate": 9.608683998927902e-05,
      "loss": 1.767,
      "step": 4270
    },
    {
      "epoch": 2.7239459029435165,
      "grad_norm": 0.6662541031837463,
      "learning_rate": 9.581881533101045e-05,
      "loss": 1.8152,
      "step": 4280
    },
    {
      "epoch": 2.7303102625298328,
      "grad_norm": 0.8199794292449951,
      "learning_rate": 9.55507906727419e-05,
      "loss": 1.8677,
      "step": 4290
    },
    {
      "epoch": 2.7366746221161495,
      "grad_norm": 0.8385306000709534,
      "learning_rate": 9.528276601447333e-05,
      "loss": 1.8913,
      "step": 4300
    },
    {
      "epoch": 2.7430389817024663,
      "grad_norm": 0.7836501002311707,
      "learning_rate": 9.501474135620477e-05,
      "loss": 1.836,
      "step": 4310
    },
    {
      "epoch": 2.749403341288783,
      "grad_norm": 0.7195981740951538,
      "learning_rate": 9.47467166979362e-05,
      "loss": 1.8886,
      "step": 4320
    },
    {
      "epoch": 2.7557677008750994,
      "grad_norm": 0.7480503916740417,
      "learning_rate": 9.447869203966765e-05,
      "loss": 1.8597,
      "step": 4330
    },
    {
      "epoch": 2.762132060461416,
      "grad_norm": 0.7861214280128479,
      "learning_rate": 9.42106673813991e-05,
      "loss": 1.9004,
      "step": 4340
    },
    {
      "epoch": 2.7684964200477324,
      "grad_norm": 0.9068483114242554,
      "learning_rate": 9.394264272313054e-05,
      "loss": 1.9039,
      "step": 4350
    },
    {
      "epoch": 2.774860779634049,
      "grad_norm": 0.6343616247177124,
      "learning_rate": 9.367461806486197e-05,
      "loss": 1.8778,
      "step": 4360
    },
    {
      "epoch": 2.781225139220366,
      "grad_norm": 0.7562837600708008,
      "learning_rate": 9.340659340659341e-05,
      "loss": 1.8213,
      "step": 4370
    },
    {
      "epoch": 2.7875894988066827,
      "grad_norm": 0.628277063369751,
      "learning_rate": 9.313856874832485e-05,
      "loss": 1.829,
      "step": 4380
    },
    {
      "epoch": 2.7939538583929995,
      "grad_norm": 0.6155074834823608,
      "learning_rate": 9.287054409005629e-05,
      "loss": 1.7552,
      "step": 4390
    },
    {
      "epoch": 2.800318217979316,
      "grad_norm": 0.6761869192123413,
      "learning_rate": 9.260251943178772e-05,
      "loss": 1.7609,
      "step": 4400
    },
    {
      "epoch": 2.800318217979316,
      "eval_loss": 2.056443929672241,
      "eval_runtime": 147.8754,
      "eval_samples_per_second": 4.727,
      "eval_steps_per_second": 0.595,
      "step": 4400
    },
    {
      "epoch": 2.8066825775656326,
      "grad_norm": 0.6976686716079712,
      "learning_rate": 9.233449477351917e-05,
      "loss": 1.822,
      "step": 4410
    },
    {
      "epoch": 2.813046937151949,
      "grad_norm": 0.5861676931381226,
      "learning_rate": 9.20664701152506e-05,
      "loss": 1.7771,
      "step": 4420
    },
    {
      "epoch": 2.8194112967382656,
      "grad_norm": 1.0042837858200073,
      "learning_rate": 9.179844545698206e-05,
      "loss": 1.8812,
      "step": 4430
    },
    {
      "epoch": 2.8257756563245824,
      "grad_norm": 0.8296209573745728,
      "learning_rate": 9.153042079871349e-05,
      "loss": 1.8311,
      "step": 4440
    },
    {
      "epoch": 2.832140015910899,
      "grad_norm": 0.762675940990448,
      "learning_rate": 9.126239614044493e-05,
      "loss": 1.8045,
      "step": 4450
    },
    {
      "epoch": 2.8385043754972155,
      "grad_norm": 0.6648589372634888,
      "learning_rate": 9.099437148217636e-05,
      "loss": 1.8479,
      "step": 4460
    },
    {
      "epoch": 2.844868735083532,
      "grad_norm": 0.6993741393089294,
      "learning_rate": 9.072634682390781e-05,
      "loss": 1.9022,
      "step": 4470
    },
    {
      "epoch": 2.851233094669849,
      "grad_norm": 1.0367189645767212,
      "learning_rate": 9.045832216563924e-05,
      "loss": 1.822,
      "step": 4480
    },
    {
      "epoch": 2.8575974542561653,
      "grad_norm": 0.9334222078323364,
      "learning_rate": 9.019029750737068e-05,
      "loss": 1.8926,
      "step": 4490
    },
    {
      "epoch": 2.863961813842482,
      "grad_norm": 0.6958246231079102,
      "learning_rate": 8.992227284910211e-05,
      "loss": 1.7021,
      "step": 4500
    },
    {
      "epoch": 2.870326173428799,
      "grad_norm": 0.6952769756317139,
      "learning_rate": 8.965424819083356e-05,
      "loss": 1.8291,
      "step": 4510
    },
    {
      "epoch": 2.8766905330151156,
      "grad_norm": 0.8250202536582947,
      "learning_rate": 8.9386223532565e-05,
      "loss": 1.8029,
      "step": 4520
    },
    {
      "epoch": 2.883054892601432,
      "grad_norm": 0.667259156703949,
      "learning_rate": 8.911819887429645e-05,
      "loss": 1.8021,
      "step": 4530
    },
    {
      "epoch": 2.8894192521877486,
      "grad_norm": 0.7195649147033691,
      "learning_rate": 8.885017421602788e-05,
      "loss": 1.786,
      "step": 4540
    },
    {
      "epoch": 2.895783611774065,
      "grad_norm": 0.6939179301261902,
      "learning_rate": 8.858214955775932e-05,
      "loss": 1.7789,
      "step": 4550
    },
    {
      "epoch": 2.9021479713603817,
      "grad_norm": 0.6592581272125244,
      "learning_rate": 8.831412489949076e-05,
      "loss": 1.8523,
      "step": 4560
    },
    {
      "epoch": 2.9085123309466985,
      "grad_norm": 0.7162583470344543,
      "learning_rate": 8.80461002412222e-05,
      "loss": 1.8535,
      "step": 4570
    },
    {
      "epoch": 2.9148766905330152,
      "grad_norm": 0.8123204708099365,
      "learning_rate": 8.777807558295363e-05,
      "loss": 1.8021,
      "step": 4580
    },
    {
      "epoch": 2.921241050119332,
      "grad_norm": 0.6430375576019287,
      "learning_rate": 8.751005092468508e-05,
      "loss": 1.6968,
      "step": 4590
    },
    {
      "epoch": 2.9276054097056483,
      "grad_norm": 0.9477987885475159,
      "learning_rate": 8.724202626641651e-05,
      "loss": 1.956,
      "step": 4600
    },
    {
      "epoch": 2.9276054097056483,
      "eval_loss": 2.049520492553711,
      "eval_runtime": 148.033,
      "eval_samples_per_second": 4.722,
      "eval_steps_per_second": 0.594,
      "step": 4600
    },
    {
      "epoch": 2.933969769291965,
      "grad_norm": 0.7897778749465942,
      "learning_rate": 8.697400160814797e-05,
      "loss": 1.81,
      "step": 4610
    },
    {
      "epoch": 2.9403341288782814,
      "grad_norm": 0.8494244813919067,
      "learning_rate": 8.67059769498794e-05,
      "loss": 1.8347,
      "step": 4620
    },
    {
      "epoch": 2.946698488464598,
      "grad_norm": 0.5788446664810181,
      "learning_rate": 8.643795229161084e-05,
      "loss": 1.8348,
      "step": 4630
    },
    {
      "epoch": 2.953062848050915,
      "grad_norm": 0.7278268337249756,
      "learning_rate": 8.616992763334227e-05,
      "loss": 1.8604,
      "step": 4640
    },
    {
      "epoch": 2.9594272076372317,
      "grad_norm": 0.6814116835594177,
      "learning_rate": 8.590190297507372e-05,
      "loss": 1.8019,
      "step": 4650
    },
    {
      "epoch": 2.965791567223548,
      "grad_norm": 0.7779012322425842,
      "learning_rate": 8.563387831680515e-05,
      "loss": 1.7801,
      "step": 4660
    },
    {
      "epoch": 2.9721559268098647,
      "grad_norm": 0.7678539156913757,
      "learning_rate": 8.53658536585366e-05,
      "loss": 1.8045,
      "step": 4670
    },
    {
      "epoch": 2.9785202863961815,
      "grad_norm": 0.7377068996429443,
      "learning_rate": 8.509782900026802e-05,
      "loss": 1.9285,
      "step": 4680
    },
    {
      "epoch": 2.984884645982498,
      "grad_norm": 0.7915878891944885,
      "learning_rate": 8.482980434199947e-05,
      "loss": 1.7767,
      "step": 4690
    },
    {
      "epoch": 2.9912490055688146,
      "grad_norm": 0.8756732940673828,
      "learning_rate": 8.45617796837309e-05,
      "loss": 1.8207,
      "step": 4700
    },
    {
      "epoch": 2.9976133651551313,
      "grad_norm": 0.6479158401489258,
      "learning_rate": 8.429375502546235e-05,
      "loss": 1.7917,
      "step": 4710
    },
    {
      "epoch": 3.003977724741448,
      "grad_norm": 0.6942206025123596,
      "learning_rate": 8.402573036719379e-05,
      "loss": 1.8547,
      "step": 4720
    },
    {
      "epoch": 3.0103420843277644,
      "grad_norm": 0.7243360877037048,
      "learning_rate": 8.375770570892522e-05,
      "loss": 1.8069,
      "step": 4730
    },
    {
      "epoch": 3.016706443914081,
      "grad_norm": 0.7227132320404053,
      "learning_rate": 8.348968105065667e-05,
      "loss": 1.7254,
      "step": 4740
    },
    {
      "epoch": 3.023070803500398,
      "grad_norm": 0.759823739528656,
      "learning_rate": 8.32216563923881e-05,
      "loss": 1.7932,
      "step": 4750
    },
    {
      "epoch": 3.0294351630867142,
      "grad_norm": 0.7988669872283936,
      "learning_rate": 8.295363173411954e-05,
      "loss": 1.7287,
      "step": 4760
    },
    {
      "epoch": 3.035799522673031,
      "grad_norm": 0.9583093523979187,
      "learning_rate": 8.268560707585097e-05,
      "loss": 1.7666,
      "step": 4770
    },
    {
      "epoch": 3.0421638822593478,
      "grad_norm": 0.7352069616317749,
      "learning_rate": 8.241758241758242e-05,
      "loss": 1.7085,
      "step": 4780
    },
    {
      "epoch": 3.048528241845664,
      "grad_norm": 0.7001526951789856,
      "learning_rate": 8.214955775931386e-05,
      "loss": 1.8003,
      "step": 4790
    },
    {
      "epoch": 3.054892601431981,
      "grad_norm": 0.7273321747779846,
      "learning_rate": 8.188153310104531e-05,
      "loss": 1.7135,
      "step": 4800
    },
    {
      "epoch": 3.054892601431981,
      "eval_loss": 2.072185754776001,
      "eval_runtime": 148.0897,
      "eval_samples_per_second": 4.72,
      "eval_steps_per_second": 0.594,
      "step": 4800
    },
    {
      "epoch": 3.0612569610182976,
      "grad_norm": 0.8517784476280212,
      "learning_rate": 8.161350844277674e-05,
      "loss": 1.7782,
      "step": 4810
    },
    {
      "epoch": 3.0676213206046143,
      "grad_norm": 0.9028149247169495,
      "learning_rate": 8.134548378450818e-05,
      "loss": 1.781,
      "step": 4820
    },
    {
      "epoch": 3.0739856801909307,
      "grad_norm": 0.833645224571228,
      "learning_rate": 8.107745912623961e-05,
      "loss": 1.7114,
      "step": 4830
    },
    {
      "epoch": 3.0803500397772474,
      "grad_norm": 0.9382058382034302,
      "learning_rate": 8.080943446797106e-05,
      "loss": 1.7086,
      "step": 4840
    },
    {
      "epoch": 3.086714399363564,
      "grad_norm": 0.6999891996383667,
      "learning_rate": 8.054140980970249e-05,
      "loss": 1.7953,
      "step": 4850
    },
    {
      "epoch": 3.0930787589498805,
      "grad_norm": 0.9365134239196777,
      "learning_rate": 8.027338515143393e-05,
      "loss": 1.7751,
      "step": 4860
    },
    {
      "epoch": 3.0994431185361973,
      "grad_norm": 0.7765035033226013,
      "learning_rate": 8.000536049316537e-05,
      "loss": 1.7286,
      "step": 4870
    },
    {
      "epoch": 3.105807478122514,
      "grad_norm": 0.7884733080863953,
      "learning_rate": 7.973733583489681e-05,
      "loss": 1.7503,
      "step": 4880
    },
    {
      "epoch": 3.1121718377088303,
      "grad_norm": 0.8381232023239136,
      "learning_rate": 7.946931117662826e-05,
      "loss": 1.7174,
      "step": 4890
    },
    {
      "epoch": 3.118536197295147,
      "grad_norm": 1.010936975479126,
      "learning_rate": 7.92012865183597e-05,
      "loss": 1.7088,
      "step": 4900
    },
    {
      "epoch": 3.124900556881464,
      "grad_norm": 1.0088167190551758,
      "learning_rate": 7.893326186009113e-05,
      "loss": 1.7895,
      "step": 4910
    },
    {
      "epoch": 3.1312649164677806,
      "grad_norm": 0.7521363496780396,
      "learning_rate": 7.866523720182258e-05,
      "loss": 1.7805,
      "step": 4920
    },
    {
      "epoch": 3.137629276054097,
      "grad_norm": 0.8821563720703125,
      "learning_rate": 7.839721254355401e-05,
      "loss": 1.7519,
      "step": 4930
    },
    {
      "epoch": 3.1439936356404137,
      "grad_norm": 0.7157553434371948,
      "learning_rate": 7.812918788528545e-05,
      "loss": 1.6679,
      "step": 4940
    },
    {
      "epoch": 3.1503579952267304,
      "grad_norm": 0.7505294680595398,
      "learning_rate": 7.786116322701688e-05,
      "loss": 1.8153,
      "step": 4950
    },
    {
      "epoch": 3.1567223548130467,
      "grad_norm": 0.786156415939331,
      "learning_rate": 7.759313856874833e-05,
      "loss": 1.724,
      "step": 4960
    },
    {
      "epoch": 3.1630867143993635,
      "grad_norm": 0.7773850560188293,
      "learning_rate": 7.732511391047976e-05,
      "loss": 1.7256,
      "step": 4970
    },
    {
      "epoch": 3.1694510739856803,
      "grad_norm": 0.8334262371063232,
      "learning_rate": 7.705708925221122e-05,
      "loss": 1.7943,
      "step": 4980
    },
    {
      "epoch": 3.175815433571997,
      "grad_norm": 0.7808427810668945,
      "learning_rate": 7.678906459394265e-05,
      "loss": 1.8014,
      "step": 4990
    },
    {
      "epoch": 3.1821797931583133,
      "grad_norm": 0.7346712350845337,
      "learning_rate": 7.652103993567409e-05,
      "loss": 1.7778,
      "step": 5000
    },
    {
      "epoch": 3.1821797931583133,
      "eval_loss": 2.0728600025177,
      "eval_runtime": 148.0528,
      "eval_samples_per_second": 4.721,
      "eval_steps_per_second": 0.594,
      "step": 5000
    },
    {
      "epoch": 3.18854415274463,
      "grad_norm": 0.7869098782539368,
      "learning_rate": 7.625301527740552e-05,
      "loss": 1.7187,
      "step": 5010
    },
    {
      "epoch": 3.194908512330947,
      "grad_norm": 0.8787582516670227,
      "learning_rate": 7.598499061913697e-05,
      "loss": 1.8201,
      "step": 5020
    },
    {
      "epoch": 3.201272871917263,
      "grad_norm": 0.9671129584312439,
      "learning_rate": 7.57169659608684e-05,
      "loss": 1.8698,
      "step": 5030
    },
    {
      "epoch": 3.20763723150358,
      "grad_norm": 0.7544390559196472,
      "learning_rate": 7.544894130259984e-05,
      "loss": 1.7016,
      "step": 5040
    },
    {
      "epoch": 3.2140015910898967,
      "grad_norm": 0.8742281794548035,
      "learning_rate": 7.518091664433128e-05,
      "loss": 1.7327,
      "step": 5050
    },
    {
      "epoch": 3.220365950676213,
      "grad_norm": 0.8098297119140625,
      "learning_rate": 7.491289198606272e-05,
      "loss": 1.6778,
      "step": 5060
    },
    {
      "epoch": 3.2267303102625298,
      "grad_norm": 0.6925668716430664,
      "learning_rate": 7.464486732779417e-05,
      "loss": 1.6655,
      "step": 5070
    },
    {
      "epoch": 3.2330946698488465,
      "grad_norm": 0.7686540484428406,
      "learning_rate": 7.437684266952561e-05,
      "loss": 1.8147,
      "step": 5080
    },
    {
      "epoch": 3.2394590294351633,
      "grad_norm": 0.8942946195602417,
      "learning_rate": 7.410881801125704e-05,
      "loss": 1.7887,
      "step": 5090
    },
    {
      "epoch": 3.2458233890214796,
      "grad_norm": 0.843956470489502,
      "learning_rate": 7.384079335298849e-05,
      "loss": 1.6972,
      "step": 5100
    },
    {
      "epoch": 3.2521877486077964,
      "grad_norm": 0.7832086086273193,
      "learning_rate": 7.357276869471992e-05,
      "loss": 1.7845,
      "step": 5110
    },
    {
      "epoch": 3.258552108194113,
      "grad_norm": 0.936199426651001,
      "learning_rate": 7.330474403645136e-05,
      "loss": 1.749,
      "step": 5120
    },
    {
      "epoch": 3.2649164677804294,
      "grad_norm": 0.8726905584335327,
      "learning_rate": 7.303671937818279e-05,
      "loss": 1.8089,
      "step": 5130
    },
    {
      "epoch": 3.271280827366746,
      "grad_norm": 0.790143609046936,
      "learning_rate": 7.276869471991424e-05,
      "loss": 1.6765,
      "step": 5140
    },
    {
      "epoch": 3.277645186953063,
      "grad_norm": 0.9275099039077759,
      "learning_rate": 7.250067006164567e-05,
      "loss": 1.7426,
      "step": 5150
    },
    {
      "epoch": 3.2840095465393793,
      "grad_norm": 0.7795479893684387,
      "learning_rate": 7.223264540337711e-05,
      "loss": 1.6494,
      "step": 5160
    },
    {
      "epoch": 3.290373906125696,
      "grad_norm": 0.6990903615951538,
      "learning_rate": 7.196462074510856e-05,
      "loss": 1.6594,
      "step": 5170
    },
    {
      "epoch": 3.296738265712013,
      "grad_norm": 1.372284173965454,
      "learning_rate": 7.169659608683999e-05,
      "loss": 1.8862,
      "step": 5180
    },
    {
      "epoch": 3.3031026252983295,
      "grad_norm": 0.9620651602745056,
      "learning_rate": 7.142857142857143e-05,
      "loss": 1.7652,
      "step": 5190
    },
    {
      "epoch": 3.309466984884646,
      "grad_norm": 0.8403136730194092,
      "learning_rate": 7.116054677030287e-05,
      "loss": 1.7141,
      "step": 5200
    },
    {
      "epoch": 3.309466984884646,
      "eval_loss": 2.076997995376587,
      "eval_runtime": 148.2261,
      "eval_samples_per_second": 4.716,
      "eval_steps_per_second": 0.594,
      "step": 5200
    },
    {
      "epoch": 3.3158313444709626,
      "grad_norm": 0.7807026505470276,
      "learning_rate": 7.089252211203431e-05,
      "loss": 1.7234,
      "step": 5210
    },
    {
      "epoch": 3.3221957040572794,
      "grad_norm": 0.7682239413261414,
      "learning_rate": 7.062449745376575e-05,
      "loss": 1.6734,
      "step": 5220
    },
    {
      "epoch": 3.3285600636435957,
      "grad_norm": 0.9692768454551697,
      "learning_rate": 7.035647279549719e-05,
      "loss": 1.7843,
      "step": 5230
    },
    {
      "epoch": 3.3349244232299124,
      "grad_norm": 0.8714150190353394,
      "learning_rate": 7.008844813722863e-05,
      "loss": 1.793,
      "step": 5240
    },
    {
      "epoch": 3.341288782816229,
      "grad_norm": 0.876067578792572,
      "learning_rate": 6.982042347896008e-05,
      "loss": 1.7312,
      "step": 5250
    },
    {
      "epoch": 3.347653142402546,
      "grad_norm": 0.6808111071586609,
      "learning_rate": 6.95523988206915e-05,
      "loss": 1.7036,
      "step": 5260
    },
    {
      "epoch": 3.3540175019888623,
      "grad_norm": 0.9997182488441467,
      "learning_rate": 6.928437416242295e-05,
      "loss": 1.7622,
      "step": 5270
    },
    {
      "epoch": 3.360381861575179,
      "grad_norm": 0.7140130996704102,
      "learning_rate": 6.901634950415438e-05,
      "loss": 1.6191,
      "step": 5280
    },
    {
      "epoch": 3.366746221161496,
      "grad_norm": 1.0388250350952148,
      "learning_rate": 6.874832484588583e-05,
      "loss": 1.7529,
      "step": 5290
    },
    {
      "epoch": 3.373110580747812,
      "grad_norm": 0.9288586974143982,
      "learning_rate": 6.848030018761726e-05,
      "loss": 1.7768,
      "step": 5300
    },
    {
      "epoch": 3.379474940334129,
      "grad_norm": 0.6923388838768005,
      "learning_rate": 6.82122755293487e-05,
      "loss": 1.7985,
      "step": 5310
    },
    {
      "epoch": 3.3858392999204456,
      "grad_norm": 0.862865149974823,
      "learning_rate": 6.794425087108013e-05,
      "loss": 1.7091,
      "step": 5320
    },
    {
      "epoch": 3.392203659506762,
      "grad_norm": 0.9498757123947144,
      "learning_rate": 6.767622621281158e-05,
      "loss": 1.7616,
      "step": 5330
    },
    {
      "epoch": 3.3985680190930787,
      "grad_norm": 0.6687164306640625,
      "learning_rate": 6.740820155454301e-05,
      "loss": 1.7375,
      "step": 5340
    },
    {
      "epoch": 3.4049323786793955,
      "grad_norm": 0.8327940702438354,
      "learning_rate": 6.714017689627447e-05,
      "loss": 1.7459,
      "step": 5350
    },
    {
      "epoch": 3.411296738265712,
      "grad_norm": 0.9308354258537292,
      "learning_rate": 6.68721522380059e-05,
      "loss": 1.8326,
      "step": 5360
    },
    {
      "epoch": 3.4176610978520285,
      "grad_norm": 0.9579125642776489,
      "learning_rate": 6.660412757973734e-05,
      "loss": 1.8312,
      "step": 5370
    },
    {
      "epoch": 3.4240254574383453,
      "grad_norm": 0.8873415589332581,
      "learning_rate": 6.633610292146878e-05,
      "loss": 1.7799,
      "step": 5380
    },
    {
      "epoch": 3.430389817024662,
      "grad_norm": 0.8579171299934387,
      "learning_rate": 6.606807826320022e-05,
      "loss": 1.687,
      "step": 5390
    },
    {
      "epoch": 3.4367541766109784,
      "grad_norm": 0.8058403134346008,
      "learning_rate": 6.580005360493165e-05,
      "loss": 1.7845,
      "step": 5400
    },
    {
      "epoch": 3.4367541766109784,
      "eval_loss": 2.077232599258423,
      "eval_runtime": 148.1482,
      "eval_samples_per_second": 4.718,
      "eval_steps_per_second": 0.594,
      "step": 5400
    },
    {
      "epoch": 3.443118536197295,
      "grad_norm": 0.7866355776786804,
      "learning_rate": 6.55320289466631e-05,
      "loss": 1.7601,
      "step": 5410
    },
    {
      "epoch": 3.449482895783612,
      "grad_norm": 0.7951905727386475,
      "learning_rate": 6.526400428839453e-05,
      "loss": 1.809,
      "step": 5420
    },
    {
      "epoch": 3.455847255369928,
      "grad_norm": 0.8892818093299866,
      "learning_rate": 6.499597963012597e-05,
      "loss": 1.7358,
      "step": 5430
    },
    {
      "epoch": 3.462211614956245,
      "grad_norm": 0.9267573356628418,
      "learning_rate": 6.472795497185742e-05,
      "loss": 1.7139,
      "step": 5440
    },
    {
      "epoch": 3.4685759745425617,
      "grad_norm": 1.0010145902633667,
      "learning_rate": 6.445993031358886e-05,
      "loss": 1.7168,
      "step": 5450
    },
    {
      "epoch": 3.4749403341288785,
      "grad_norm": 0.9675536751747131,
      "learning_rate": 6.419190565532029e-05,
      "loss": 1.7744,
      "step": 5460
    },
    {
      "epoch": 3.481304693715195,
      "grad_norm": 0.899218738079071,
      "learning_rate": 6.392388099705174e-05,
      "loss": 1.7652,
      "step": 5470
    },
    {
      "epoch": 3.4876690533015116,
      "grad_norm": 0.8318515419960022,
      "learning_rate": 6.365585633878317e-05,
      "loss": 1.7848,
      "step": 5480
    },
    {
      "epoch": 3.4940334128878283,
      "grad_norm": 0.8025091290473938,
      "learning_rate": 6.338783168051461e-05,
      "loss": 1.7213,
      "step": 5490
    },
    {
      "epoch": 3.5003977724741446,
      "grad_norm": 0.8873046636581421,
      "learning_rate": 6.311980702224604e-05,
      "loss": 1.7689,
      "step": 5500
    },
    {
      "epoch": 3.5067621320604614,
      "grad_norm": 0.8379963040351868,
      "learning_rate": 6.285178236397749e-05,
      "loss": 1.7253,
      "step": 5510
    },
    {
      "epoch": 3.513126491646778,
      "grad_norm": 0.7456035614013672,
      "learning_rate": 6.258375770570892e-05,
      "loss": 1.6317,
      "step": 5520
    },
    {
      "epoch": 3.519490851233095,
      "grad_norm": 0.8500900864601135,
      "learning_rate": 6.231573304744038e-05,
      "loss": 1.6634,
      "step": 5530
    },
    {
      "epoch": 3.5258552108194112,
      "grad_norm": 0.7256792783737183,
      "learning_rate": 6.204770838917181e-05,
      "loss": 1.6432,
      "step": 5540
    },
    {
      "epoch": 3.532219570405728,
      "grad_norm": 0.8077070713043213,
      "learning_rate": 6.177968373090325e-05,
      "loss": 1.691,
      "step": 5550
    },
    {
      "epoch": 3.5385839299920443,
      "grad_norm": 0.7831115126609802,
      "learning_rate": 6.151165907263469e-05,
      "loss": 1.7742,
      "step": 5560
    },
    {
      "epoch": 3.544948289578361,
      "grad_norm": 0.8689872026443481,
      "learning_rate": 6.124363441436613e-05,
      "loss": 1.7082,
      "step": 5570
    },
    {
      "epoch": 3.551312649164678,
      "grad_norm": 0.8315632343292236,
      "learning_rate": 6.097560975609756e-05,
      "loss": 1.7605,
      "step": 5580
    },
    {
      "epoch": 3.5576770087509946,
      "grad_norm": 0.7368837594985962,
      "learning_rate": 6.0707585097829e-05,
      "loss": 1.6766,
      "step": 5590
    },
    {
      "epoch": 3.5640413683373113,
      "grad_norm": 0.694923996925354,
      "learning_rate": 6.043956043956044e-05,
      "loss": 1.7511,
      "step": 5600
    },
    {
      "epoch": 3.5640413683373113,
      "eval_loss": 2.0747342109680176,
      "eval_runtime": 148.047,
      "eval_samples_per_second": 4.721,
      "eval_steps_per_second": 0.594,
      "step": 5600
    },
    {
      "epoch": 3.5704057279236276,
      "grad_norm": 0.8004775643348694,
      "learning_rate": 6.0171535781291875e-05,
      "loss": 1.6928,
      "step": 5610
    },
    {
      "epoch": 3.5767700875099444,
      "grad_norm": 0.8305127024650574,
      "learning_rate": 5.9903511123023326e-05,
      "loss": 1.7258,
      "step": 5620
    },
    {
      "epoch": 3.5831344470962607,
      "grad_norm": 0.9474819898605347,
      "learning_rate": 5.9635486464754764e-05,
      "loss": 1.6536,
      "step": 5630
    },
    {
      "epoch": 3.5894988066825775,
      "grad_norm": 0.8134638667106628,
      "learning_rate": 5.93674618064862e-05,
      "loss": 1.7873,
      "step": 5640
    },
    {
      "epoch": 3.5958631662688942,
      "grad_norm": 1.0353847742080688,
      "learning_rate": 5.909943714821764e-05,
      "loss": 1.799,
      "step": 5650
    },
    {
      "epoch": 3.602227525855211,
      "grad_norm": 0.911791205406189,
      "learning_rate": 5.883141248994908e-05,
      "loss": 1.8114,
      "step": 5660
    },
    {
      "epoch": 3.6085918854415273,
      "grad_norm": 0.7831370830535889,
      "learning_rate": 5.8563387831680516e-05,
      "loss": 1.8049,
      "step": 5670
    },
    {
      "epoch": 3.614956245027844,
      "grad_norm": 0.7753221392631531,
      "learning_rate": 5.8295363173411954e-05,
      "loss": 1.7278,
      "step": 5680
    },
    {
      "epoch": 3.621320604614161,
      "grad_norm": 0.9296595454216003,
      "learning_rate": 5.802733851514339e-05,
      "loss": 1.7929,
      "step": 5690
    },
    {
      "epoch": 3.627684964200477,
      "grad_norm": 0.8798409700393677,
      "learning_rate": 5.775931385687483e-05,
      "loss": 1.7515,
      "step": 5700
    },
    {
      "epoch": 3.634049323786794,
      "grad_norm": 0.7770968675613403,
      "learning_rate": 5.749128919860628e-05,
      "loss": 1.6589,
      "step": 5710
    },
    {
      "epoch": 3.6404136833731107,
      "grad_norm": 0.864413321018219,
      "learning_rate": 5.722326454033772e-05,
      "loss": 1.6674,
      "step": 5720
    },
    {
      "epoch": 3.6467780429594274,
      "grad_norm": 0.8830629587173462,
      "learning_rate": 5.695523988206916e-05,
      "loss": 1.8372,
      "step": 5730
    },
    {
      "epoch": 3.6531424025457437,
      "grad_norm": 0.7944042086601257,
      "learning_rate": 5.6687215223800595e-05,
      "loss": 1.7549,
      "step": 5740
    },
    {
      "epoch": 3.6595067621320605,
      "grad_norm": 0.8992975950241089,
      "learning_rate": 5.641919056553203e-05,
      "loss": 1.8344,
      "step": 5750
    },
    {
      "epoch": 3.665871121718377,
      "grad_norm": 0.857367217540741,
      "learning_rate": 5.615116590726347e-05,
      "loss": 1.6987,
      "step": 5760
    },
    {
      "epoch": 3.6722354813046936,
      "grad_norm": 1.0743602514266968,
      "learning_rate": 5.588314124899491e-05,
      "loss": 1.7514,
      "step": 5770
    },
    {
      "epoch": 3.6785998408910103,
      "grad_norm": 1.0007842779159546,
      "learning_rate": 5.561511659072635e-05,
      "loss": 1.769,
      "step": 5780
    },
    {
      "epoch": 3.684964200477327,
      "grad_norm": 0.7700207233428955,
      "learning_rate": 5.5347091932457785e-05,
      "loss": 1.7985,
      "step": 5790
    },
    {
      "epoch": 3.691328560063644,
      "grad_norm": 0.9005807638168335,
      "learning_rate": 5.5079067274189236e-05,
      "loss": 1.7182,
      "step": 5800
    },
    {
      "epoch": 3.691328560063644,
      "eval_loss": 2.074784755706787,
      "eval_runtime": 148.2778,
      "eval_samples_per_second": 4.714,
      "eval_steps_per_second": 0.593,
      "step": 5800
    },
    {
      "epoch": 3.69769291964996,
      "grad_norm": 1.1645561456680298,
      "learning_rate": 5.4811042615920674e-05,
      "loss": 1.7252,
      "step": 5810
    },
    {
      "epoch": 3.704057279236277,
      "grad_norm": 0.7618228793144226,
      "learning_rate": 5.454301795765211e-05,
      "loss": 1.6762,
      "step": 5820
    },
    {
      "epoch": 3.7104216388225932,
      "grad_norm": 0.8325057029724121,
      "learning_rate": 5.427499329938355e-05,
      "loss": 1.8121,
      "step": 5830
    },
    {
      "epoch": 3.71678599840891,
      "grad_norm": 0.887194037437439,
      "learning_rate": 5.400696864111499e-05,
      "loss": 1.7065,
      "step": 5840
    },
    {
      "epoch": 3.7231503579952268,
      "grad_norm": 0.9085360765457153,
      "learning_rate": 5.3738943982846426e-05,
      "loss": 1.7396,
      "step": 5850
    },
    {
      "epoch": 3.7295147175815435,
      "grad_norm": 0.9852733016014099,
      "learning_rate": 5.3470919324577864e-05,
      "loss": 1.7255,
      "step": 5860
    },
    {
      "epoch": 3.73587907716786,
      "grad_norm": 0.9124417304992676,
      "learning_rate": 5.32028946663093e-05,
      "loss": 1.7334,
      "step": 5870
    },
    {
      "epoch": 3.7422434367541766,
      "grad_norm": 0.9997866749763489,
      "learning_rate": 5.293487000804074e-05,
      "loss": 1.7358,
      "step": 5880
    },
    {
      "epoch": 3.7486077963404933,
      "grad_norm": 0.9221978187561035,
      "learning_rate": 5.2666845349772184e-05,
      "loss": 1.7414,
      "step": 5890
    },
    {
      "epoch": 3.7549721559268097,
      "grad_norm": 0.8439065217971802,
      "learning_rate": 5.239882069150362e-05,
      "loss": 1.7997,
      "step": 5900
    },
    {
      "epoch": 3.7613365155131264,
      "grad_norm": 1.019063115119934,
      "learning_rate": 5.213079603323506e-05,
      "loss": 1.744,
      "step": 5910
    },
    {
      "epoch": 3.767700875099443,
      "grad_norm": 0.9700008630752563,
      "learning_rate": 5.18627713749665e-05,
      "loss": 1.7986,
      "step": 5920
    },
    {
      "epoch": 3.77406523468576,
      "grad_norm": 0.9729311466217041,
      "learning_rate": 5.1594746716697936e-05,
      "loss": 1.794,
      "step": 5930
    },
    {
      "epoch": 3.7804295942720763,
      "grad_norm": 0.8326085209846497,
      "learning_rate": 5.1326722058429374e-05,
      "loss": 1.7944,
      "step": 5940
    },
    {
      "epoch": 3.786793953858393,
      "grad_norm": 0.8839120268821716,
      "learning_rate": 5.105869740016081e-05,
      "loss": 1.7404,
      "step": 5950
    },
    {
      "epoch": 3.7931583134447098,
      "grad_norm": 0.9986181259155273,
      "learning_rate": 5.079067274189226e-05,
      "loss": 1.7406,
      "step": 5960
    },
    {
      "epoch": 3.799522673031026,
      "grad_norm": 0.9168634414672852,
      "learning_rate": 5.0522648083623695e-05,
      "loss": 1.7436,
      "step": 5970
    },
    {
      "epoch": 3.805887032617343,
      "grad_norm": 0.9482905268669128,
      "learning_rate": 5.025462342535513e-05,
      "loss": 1.7866,
      "step": 5980
    },
    {
      "epoch": 3.8122513922036596,
      "grad_norm": 0.8043409585952759,
      "learning_rate": 4.998659876708657e-05,
      "loss": 1.6654,
      "step": 5990
    },
    {
      "epoch": 3.8186157517899764,
      "grad_norm": 0.6823076605796814,
      "learning_rate": 4.971857410881801e-05,
      "loss": 1.687,
      "step": 6000
    },
    {
      "epoch": 3.8186157517899764,
      "eval_loss": 2.069828748703003,
      "eval_runtime": 148.2055,
      "eval_samples_per_second": 4.716,
      "eval_steps_per_second": 0.594,
      "step": 6000
    },
    {
      "epoch": 3.8249801113762927,
      "grad_norm": 0.8273839950561523,
      "learning_rate": 4.945054945054945e-05,
      "loss": 1.8513,
      "step": 6010
    },
    {
      "epoch": 3.8313444709626094,
      "grad_norm": 0.8958255648612976,
      "learning_rate": 4.918252479228089e-05,
      "loss": 1.654,
      "step": 6020
    },
    {
      "epoch": 3.8377088305489258,
      "grad_norm": 0.7159304618835449,
      "learning_rate": 4.891450013401233e-05,
      "loss": 1.6987,
      "step": 6030
    },
    {
      "epoch": 3.8440731901352425,
      "grad_norm": 1.0386284589767456,
      "learning_rate": 4.864647547574377e-05,
      "loss": 1.7931,
      "step": 6040
    },
    {
      "epoch": 3.8504375497215593,
      "grad_norm": 0.956386148929596,
      "learning_rate": 4.837845081747521e-05,
      "loss": 1.724,
      "step": 6050
    },
    {
      "epoch": 3.856801909307876,
      "grad_norm": 0.8470115065574646,
      "learning_rate": 4.811042615920665e-05,
      "loss": 1.7012,
      "step": 6060
    },
    {
      "epoch": 3.863166268894193,
      "grad_norm": 0.7908268570899963,
      "learning_rate": 4.784240150093809e-05,
      "loss": 1.7448,
      "step": 6070
    },
    {
      "epoch": 3.869530628480509,
      "grad_norm": 0.8952659964561462,
      "learning_rate": 4.7574376842669526e-05,
      "loss": 1.6862,
      "step": 6080
    },
    {
      "epoch": 3.875894988066826,
      "grad_norm": 0.8395251035690308,
      "learning_rate": 4.7306352184400963e-05,
      "loss": 1.6691,
      "step": 6090
    },
    {
      "epoch": 3.882259347653142,
      "grad_norm": 0.8380945920944214,
      "learning_rate": 4.703832752613241e-05,
      "loss": 1.7769,
      "step": 6100
    },
    {
      "epoch": 3.888623707239459,
      "grad_norm": 0.9713082313537598,
      "learning_rate": 4.6770302867863846e-05,
      "loss": 1.7934,
      "step": 6110
    },
    {
      "epoch": 3.8949880668257757,
      "grad_norm": 0.8252938389778137,
      "learning_rate": 4.6502278209595284e-05,
      "loss": 1.7765,
      "step": 6120
    },
    {
      "epoch": 3.9013524264120925,
      "grad_norm": 0.943266749382019,
      "learning_rate": 4.623425355132672e-05,
      "loss": 1.6994,
      "step": 6130
    },
    {
      "epoch": 3.9077167859984088,
      "grad_norm": 0.7167627215385437,
      "learning_rate": 4.596622889305816e-05,
      "loss": 1.672,
      "step": 6140
    },
    {
      "epoch": 3.9140811455847255,
      "grad_norm": 0.7728689312934875,
      "learning_rate": 4.5698204234789605e-05,
      "loss": 1.7306,
      "step": 6150
    },
    {
      "epoch": 3.9204455051710423,
      "grad_norm": 0.8333115577697754,
      "learning_rate": 4.543017957652104e-05,
      "loss": 1.7826,
      "step": 6160
    },
    {
      "epoch": 3.9268098647573586,
      "grad_norm": 0.82242351770401,
      "learning_rate": 4.516215491825248e-05,
      "loss": 1.7806,
      "step": 6170
    },
    {
      "epoch": 3.9331742243436754,
      "grad_norm": 0.9405356645584106,
      "learning_rate": 4.489413025998392e-05,
      "loss": 1.8329,
      "step": 6180
    },
    {
      "epoch": 3.939538583929992,
      "grad_norm": 0.8705261945724487,
      "learning_rate": 4.462610560171536e-05,
      "loss": 1.7446,
      "step": 6190
    },
    {
      "epoch": 3.945902943516309,
      "grad_norm": 0.8149329423904419,
      "learning_rate": 4.43580809434468e-05,
      "loss": 1.7863,
      "step": 6200
    },
    {
      "epoch": 3.945902943516309,
      "eval_loss": 2.0754096508026123,
      "eval_runtime": 148.2998,
      "eval_samples_per_second": 4.713,
      "eval_steps_per_second": 0.593,
      "step": 6200
    },
    {
      "epoch": 3.952267303102625,
      "grad_norm": 1.0148849487304688,
      "learning_rate": 4.409005628517824e-05,
      "loss": 1.7728,
      "step": 6210
    },
    {
      "epoch": 3.958631662688942,
      "grad_norm": 0.7949527502059937,
      "learning_rate": 4.382203162690968e-05,
      "loss": 1.7671,
      "step": 6220
    },
    {
      "epoch": 3.9649960222752587,
      "grad_norm": 0.9477655291557312,
      "learning_rate": 4.3554006968641115e-05,
      "loss": 1.7334,
      "step": 6230
    },
    {
      "epoch": 3.971360381861575,
      "grad_norm": 0.9778335094451904,
      "learning_rate": 4.328598231037256e-05,
      "loss": 1.8914,
      "step": 6240
    },
    {
      "epoch": 3.977724741447892,
      "grad_norm": 0.7764614820480347,
      "learning_rate": 4.3017957652104e-05,
      "loss": 1.6991,
      "step": 6250
    },
    {
      "epoch": 3.9840891010342085,
      "grad_norm": 0.7834045886993408,
      "learning_rate": 4.2749932993835436e-05,
      "loss": 1.6608,
      "step": 6260
    },
    {
      "epoch": 3.9904534606205253,
      "grad_norm": 1.0071632862091064,
      "learning_rate": 4.2481908335566873e-05,
      "loss": 1.8461,
      "step": 6270
    },
    {
      "epoch": 3.9968178202068416,
      "grad_norm": 0.810790479183197,
      "learning_rate": 4.221388367729832e-05,
      "loss": 1.6944,
      "step": 6280
    },
    {
      "epoch": 4.003182179793158,
      "grad_norm": 0.8231973052024841,
      "learning_rate": 4.1945859019029756e-05,
      "loss": 1.8552,
      "step": 6290
    },
    {
      "epoch": 4.009546539379475,
      "grad_norm": 0.8707797527313232,
      "learning_rate": 4.1677834360761194e-05,
      "loss": 1.643,
      "step": 6300
    },
    {
      "epoch": 4.0159108989657915,
      "grad_norm": 0.8835113048553467,
      "learning_rate": 4.140980970249263e-05,
      "loss": 1.6822,
      "step": 6310
    },
    {
      "epoch": 4.022275258552108,
      "grad_norm": 0.8023215532302856,
      "learning_rate": 4.114178504422407e-05,
      "loss": 1.6996,
      "step": 6320
    },
    {
      "epoch": 4.028639618138425,
      "grad_norm": 0.8778082728385925,
      "learning_rate": 4.0873760385955515e-05,
      "loss": 1.6936,
      "step": 6330
    },
    {
      "epoch": 4.035003977724742,
      "grad_norm": 0.9891757369041443,
      "learning_rate": 4.060573572768695e-05,
      "loss": 1.5913,
      "step": 6340
    },
    {
      "epoch": 4.0413683373110585,
      "grad_norm": 0.9371444582939148,
      "learning_rate": 4.033771106941839e-05,
      "loss": 1.6904,
      "step": 6350
    },
    {
      "epoch": 4.047732696897374,
      "grad_norm": 0.8078378438949585,
      "learning_rate": 4.006968641114983e-05,
      "loss": 1.7037,
      "step": 6360
    },
    {
      "epoch": 4.054097056483691,
      "grad_norm": 0.9786196947097778,
      "learning_rate": 3.9801661752881266e-05,
      "loss": 1.6438,
      "step": 6370
    },
    {
      "epoch": 4.060461416070008,
      "grad_norm": 0.8528961539268494,
      "learning_rate": 3.9533637094612704e-05,
      "loss": 1.6844,
      "step": 6380
    },
    {
      "epoch": 4.066825775656325,
      "grad_norm": 0.8878600597381592,
      "learning_rate": 3.926561243634415e-05,
      "loss": 1.665,
      "step": 6390
    },
    {
      "epoch": 4.073190135242641,
      "grad_norm": 0.8704801201820374,
      "learning_rate": 3.899758777807559e-05,
      "loss": 1.6473,
      "step": 6400
    },
    {
      "epoch": 4.073190135242641,
      "eval_loss": 2.0923380851745605,
      "eval_runtime": 147.9907,
      "eval_samples_per_second": 4.723,
      "eval_steps_per_second": 0.595,
      "step": 6400
    },
    {
      "epoch": 4.079554494828958,
      "grad_norm": 0.9819457530975342,
      "learning_rate": 3.8729563119807025e-05,
      "loss": 1.6231,
      "step": 6410
    },
    {
      "epoch": 4.085918854415274,
      "grad_norm": 0.771224856376648,
      "learning_rate": 3.846153846153846e-05,
      "loss": 1.6729,
      "step": 6420
    },
    {
      "epoch": 4.092283214001591,
      "grad_norm": 0.8287114500999451,
      "learning_rate": 3.81935138032699e-05,
      "loss": 1.7428,
      "step": 6430
    },
    {
      "epoch": 4.0986475735879075,
      "grad_norm": 0.8633162975311279,
      "learning_rate": 3.792548914500134e-05,
      "loss": 1.7804,
      "step": 6440
    },
    {
      "epoch": 4.105011933174224,
      "grad_norm": 0.9253461360931396,
      "learning_rate": 3.765746448673278e-05,
      "loss": 1.7442,
      "step": 6450
    },
    {
      "epoch": 4.111376292760541,
      "grad_norm": 1.1544286012649536,
      "learning_rate": 3.7389439828464215e-05,
      "loss": 1.679,
      "step": 6460
    },
    {
      "epoch": 4.117740652346858,
      "grad_norm": 1.15193510055542,
      "learning_rate": 3.712141517019566e-05,
      "loss": 1.7857,
      "step": 6470
    },
    {
      "epoch": 4.124105011933175,
      "grad_norm": 0.9372014999389648,
      "learning_rate": 3.68533905119271e-05,
      "loss": 1.684,
      "step": 6480
    },
    {
      "epoch": 4.1304693715194905,
      "grad_norm": 1.0935885906219482,
      "learning_rate": 3.6585365853658535e-05,
      "loss": 1.692,
      "step": 6490
    },
    {
      "epoch": 4.136833731105807,
      "grad_norm": 0.8390401005744934,
      "learning_rate": 3.631734119538997e-05,
      "loss": 1.7213,
      "step": 6500
    },
    {
      "epoch": 4.143198090692124,
      "grad_norm": 0.8648762702941895,
      "learning_rate": 3.604931653712142e-05,
      "loss": 1.6244,
      "step": 6510
    },
    {
      "epoch": 4.149562450278441,
      "grad_norm": 0.9697524905204773,
      "learning_rate": 3.5781291878852856e-05,
      "loss": 1.7068,
      "step": 6520
    },
    {
      "epoch": 4.1559268098647575,
      "grad_norm": 1.0504541397094727,
      "learning_rate": 3.5513267220584294e-05,
      "loss": 1.7078,
      "step": 6530
    },
    {
      "epoch": 4.162291169451074,
      "grad_norm": 0.8408516645431519,
      "learning_rate": 3.524524256231573e-05,
      "loss": 1.6616,
      "step": 6540
    },
    {
      "epoch": 4.168655529037391,
      "grad_norm": 1.012069821357727,
      "learning_rate": 3.497721790404717e-05,
      "loss": 1.6873,
      "step": 6550
    },
    {
      "epoch": 4.175019888623707,
      "grad_norm": 0.921043336391449,
      "learning_rate": 3.4709193245778614e-05,
      "loss": 1.7,
      "step": 6560
    },
    {
      "epoch": 4.181384248210024,
      "grad_norm": 0.8636658787727356,
      "learning_rate": 3.444116858751005e-05,
      "loss": 1.7073,
      "step": 6570
    },
    {
      "epoch": 4.18774860779634,
      "grad_norm": 0.9641143083572388,
      "learning_rate": 3.417314392924149e-05,
      "loss": 1.6295,
      "step": 6580
    },
    {
      "epoch": 4.194112967382657,
      "grad_norm": 0.9857779145240784,
      "learning_rate": 3.390511927097293e-05,
      "loss": 1.6359,
      "step": 6590
    },
    {
      "epoch": 4.200477326968974,
      "grad_norm": 0.9171356558799744,
      "learning_rate": 3.363709461270437e-05,
      "loss": 1.6956,
      "step": 6600
    },
    {
      "epoch": 4.200477326968974,
      "eval_loss": 2.0961697101593018,
      "eval_runtime": 147.9724,
      "eval_samples_per_second": 4.724,
      "eval_steps_per_second": 0.595,
      "step": 6600
    },
    {
      "epoch": 4.206841686555291,
      "grad_norm": 0.8340641856193542,
      "learning_rate": 3.336906995443581e-05,
      "loss": 1.7382,
      "step": 6610
    },
    {
      "epoch": 4.213206046141607,
      "grad_norm": 0.9751409292221069,
      "learning_rate": 3.310104529616725e-05,
      "loss": 1.6242,
      "step": 6620
    },
    {
      "epoch": 4.219570405727923,
      "grad_norm": 0.8345038890838623,
      "learning_rate": 3.283302063789869e-05,
      "loss": 1.751,
      "step": 6630
    },
    {
      "epoch": 4.22593476531424,
      "grad_norm": 1.056457281112671,
      "learning_rate": 3.2564995979630125e-05,
      "loss": 1.7136,
      "step": 6640
    },
    {
      "epoch": 4.232299124900557,
      "grad_norm": 0.9570945501327515,
      "learning_rate": 3.229697132136157e-05,
      "loss": 1.7077,
      "step": 6650
    },
    {
      "epoch": 4.238663484486874,
      "grad_norm": 1.0106182098388672,
      "learning_rate": 3.202894666309301e-05,
      "loss": 1.7478,
      "step": 6660
    },
    {
      "epoch": 4.24502784407319,
      "grad_norm": 0.8474522829055786,
      "learning_rate": 3.1760922004824445e-05,
      "loss": 1.6641,
      "step": 6670
    },
    {
      "epoch": 4.251392203659507,
      "grad_norm": 1.143580675125122,
      "learning_rate": 3.149289734655588e-05,
      "loss": 1.7077,
      "step": 6680
    },
    {
      "epoch": 4.257756563245824,
      "grad_norm": 1.077797770500183,
      "learning_rate": 3.122487268828733e-05,
      "loss": 1.6668,
      "step": 6690
    },
    {
      "epoch": 4.26412092283214,
      "grad_norm": 0.9555182456970215,
      "learning_rate": 3.0956848030018766e-05,
      "loss": 1.7009,
      "step": 6700
    },
    {
      "epoch": 4.2704852824184565,
      "grad_norm": 1.0049580335617065,
      "learning_rate": 3.0688823371750204e-05,
      "loss": 1.7471,
      "step": 6710
    },
    {
      "epoch": 4.276849642004773,
      "grad_norm": 1.1180287599563599,
      "learning_rate": 3.042079871348164e-05,
      "loss": 1.6686,
      "step": 6720
    },
    {
      "epoch": 4.28321400159109,
      "grad_norm": 0.869735598564148,
      "learning_rate": 3.015277405521308e-05,
      "loss": 1.708,
      "step": 6730
    },
    {
      "epoch": 4.289578361177407,
      "grad_norm": 0.7810156941413879,
      "learning_rate": 2.988474939694452e-05,
      "loss": 1.709,
      "step": 6740
    },
    {
      "epoch": 4.2959427207637235,
      "grad_norm": 0.9699799418449402,
      "learning_rate": 2.9616724738675962e-05,
      "loss": 1.7217,
      "step": 6750
    },
    {
      "epoch": 4.302307080350039,
      "grad_norm": 1.0172406435012817,
      "learning_rate": 2.93487000804074e-05,
      "loss": 1.652,
      "step": 6760
    },
    {
      "epoch": 4.308671439936356,
      "grad_norm": 0.9090523719787598,
      "learning_rate": 2.9080675422138838e-05,
      "loss": 1.7204,
      "step": 6770
    },
    {
      "epoch": 4.315035799522673,
      "grad_norm": 0.9218752384185791,
      "learning_rate": 2.8812650763870276e-05,
      "loss": 1.629,
      "step": 6780
    },
    {
      "epoch": 4.32140015910899,
      "grad_norm": 1.0365737676620483,
      "learning_rate": 2.8544626105601717e-05,
      "loss": 1.7026,
      "step": 6790
    },
    {
      "epoch": 4.327764518695306,
      "grad_norm": 0.9580086469650269,
      "learning_rate": 2.8276601447333155e-05,
      "loss": 1.6382,
      "step": 6800
    },
    {
      "epoch": 4.327764518695306,
      "eval_loss": 2.0959272384643555,
      "eval_runtime": 147.9919,
      "eval_samples_per_second": 4.723,
      "eval_steps_per_second": 0.595,
      "step": 6800
    },
    {
      "epoch": 4.334128878281623,
      "grad_norm": 0.8678130507469177,
      "learning_rate": 2.8008576789064593e-05,
      "loss": 1.6304,
      "step": 6810
    },
    {
      "epoch": 4.34049323786794,
      "grad_norm": 1.0244358777999878,
      "learning_rate": 2.774055213079603e-05,
      "loss": 1.7266,
      "step": 6820
    },
    {
      "epoch": 4.346857597454256,
      "grad_norm": 1.0686124563217163,
      "learning_rate": 2.7472527472527476e-05,
      "loss": 1.6952,
      "step": 6830
    },
    {
      "epoch": 4.353221957040573,
      "grad_norm": 0.8572448492050171,
      "learning_rate": 2.7204502814258914e-05,
      "loss": 1.6429,
      "step": 6840
    },
    {
      "epoch": 4.359586316626889,
      "grad_norm": 0.9045402407646179,
      "learning_rate": 2.6936478155990352e-05,
      "loss": 1.6398,
      "step": 6850
    },
    {
      "epoch": 4.365950676213206,
      "grad_norm": 1.0194764137268066,
      "learning_rate": 2.666845349772179e-05,
      "loss": 1.7431,
      "step": 6860
    },
    {
      "epoch": 4.372315035799523,
      "grad_norm": 0.9238032102584839,
      "learning_rate": 2.6400428839453228e-05,
      "loss": 1.6816,
      "step": 6870
    },
    {
      "epoch": 4.37867939538584,
      "grad_norm": 0.8592289686203003,
      "learning_rate": 2.6132404181184672e-05,
      "loss": 1.5433,
      "step": 6880
    },
    {
      "epoch": 4.3850437549721555,
      "grad_norm": 0.9138746857643127,
      "learning_rate": 2.586437952291611e-05,
      "loss": 1.6587,
      "step": 6890
    },
    {
      "epoch": 4.391408114558472,
      "grad_norm": 1.0162009000778198,
      "learning_rate": 2.5596354864647548e-05,
      "loss": 1.6566,
      "step": 6900
    },
    {
      "epoch": 4.397772474144789,
      "grad_norm": 0.9278168082237244,
      "learning_rate": 2.5328330206378986e-05,
      "loss": 1.6965,
      "step": 6910
    },
    {
      "epoch": 4.404136833731106,
      "grad_norm": 0.9810173511505127,
      "learning_rate": 2.506030554811043e-05,
      "loss": 1.7651,
      "step": 6920
    },
    {
      "epoch": 4.4105011933174225,
      "grad_norm": 0.9656720757484436,
      "learning_rate": 2.479228088984187e-05,
      "loss": 1.6168,
      "step": 6930
    },
    {
      "epoch": 4.416865552903739,
      "grad_norm": 0.9676253795623779,
      "learning_rate": 2.4524256231573307e-05,
      "loss": 1.8039,
      "step": 6940
    },
    {
      "epoch": 4.423229912490056,
      "grad_norm": 1.0883781909942627,
      "learning_rate": 2.4256231573304745e-05,
      "loss": 1.6877,
      "step": 6950
    },
    {
      "epoch": 4.429594272076372,
      "grad_norm": 0.852455735206604,
      "learning_rate": 2.3988206915036186e-05,
      "loss": 1.6746,
      "step": 6960
    },
    {
      "epoch": 4.435958631662689,
      "grad_norm": 1.059017539024353,
      "learning_rate": 2.3720182256767624e-05,
      "loss": 1.6158,
      "step": 6970
    },
    {
      "epoch": 4.442322991249005,
      "grad_norm": 0.8664741516113281,
      "learning_rate": 2.3452157598499065e-05,
      "loss": 1.665,
      "step": 6980
    },
    {
      "epoch": 4.448687350835322,
      "grad_norm": 1.0683914422988892,
      "learning_rate": 2.3184132940230503e-05,
      "loss": 1.7595,
      "step": 6990
    },
    {
      "epoch": 4.455051710421639,
      "grad_norm": 0.8703308701515198,
      "learning_rate": 2.291610828196194e-05,
      "loss": 1.6966,
      "step": 7000
    },
    {
      "epoch": 4.455051710421639,
      "eval_loss": 2.0977044105529785,
      "eval_runtime": 147.9798,
      "eval_samples_per_second": 4.724,
      "eval_steps_per_second": 0.595,
      "step": 7000
    },
    {
      "epoch": 4.461416070007956,
      "grad_norm": 1.159105896949768,
      "learning_rate": 2.264808362369338e-05,
      "loss": 1.6904,
      "step": 7010
    },
    {
      "epoch": 4.4677804295942725,
      "grad_norm": 0.8777647018432617,
      "learning_rate": 2.238005896542482e-05,
      "loss": 1.5865,
      "step": 7020
    },
    {
      "epoch": 4.474144789180588,
      "grad_norm": 1.1626890897750854,
      "learning_rate": 2.211203430715626e-05,
      "loss": 1.7198,
      "step": 7030
    },
    {
      "epoch": 4.480509148766905,
      "grad_norm": 1.0152833461761475,
      "learning_rate": 2.1844009648887696e-05,
      "loss": 1.7082,
      "step": 7040
    },
    {
      "epoch": 4.486873508353222,
      "grad_norm": 1.0908278226852417,
      "learning_rate": 2.1575984990619138e-05,
      "loss": 1.6664,
      "step": 7050
    },
    {
      "epoch": 4.493237867939539,
      "grad_norm": 0.8101767301559448,
      "learning_rate": 2.1307960332350576e-05,
      "loss": 1.5943,
      "step": 7060
    },
    {
      "epoch": 4.499602227525855,
      "grad_norm": 0.8458892703056335,
      "learning_rate": 2.1039935674082017e-05,
      "loss": 1.7386,
      "step": 7070
    },
    {
      "epoch": 4.505966587112172,
      "grad_norm": 1.0524476766586304,
      "learning_rate": 2.0771911015813455e-05,
      "loss": 1.6952,
      "step": 7080
    },
    {
      "epoch": 4.512330946698489,
      "grad_norm": 0.956927478313446,
      "learning_rate": 2.0503886357544896e-05,
      "loss": 1.7752,
      "step": 7090
    },
    {
      "epoch": 4.518695306284805,
      "grad_norm": 0.8844727277755737,
      "learning_rate": 2.0235861699276334e-05,
      "loss": 1.6848,
      "step": 7100
    },
    {
      "epoch": 4.5250596658711215,
      "grad_norm": 0.9831442832946777,
      "learning_rate": 1.9967837041007772e-05,
      "loss": 1.7832,
      "step": 7110
    },
    {
      "epoch": 4.531424025457438,
      "grad_norm": 1.1607903242111206,
      "learning_rate": 1.9699812382739213e-05,
      "loss": 1.7151,
      "step": 7120
    },
    {
      "epoch": 4.537788385043755,
      "grad_norm": 1.0348821878433228,
      "learning_rate": 1.943178772447065e-05,
      "loss": 1.6595,
      "step": 7130
    },
    {
      "epoch": 4.544152744630072,
      "grad_norm": 1.5513110160827637,
      "learning_rate": 1.9163763066202093e-05,
      "loss": 1.6244,
      "step": 7140
    },
    {
      "epoch": 4.5505171042163886,
      "grad_norm": 0.932761013507843,
      "learning_rate": 1.889573840793353e-05,
      "loss": 1.7509,
      "step": 7150
    },
    {
      "epoch": 4.556881463802705,
      "grad_norm": 0.8626664876937866,
      "learning_rate": 1.8627713749664972e-05,
      "loss": 1.5683,
      "step": 7160
    },
    {
      "epoch": 4.563245823389021,
      "grad_norm": 0.964782178401947,
      "learning_rate": 1.835968909139641e-05,
      "loss": 1.716,
      "step": 7170
    },
    {
      "epoch": 4.569610182975338,
      "grad_norm": 0.8945199847221375,
      "learning_rate": 1.8091664433127848e-05,
      "loss": 1.7069,
      "step": 7180
    },
    {
      "epoch": 4.575974542561655,
      "grad_norm": 0.9171817898750305,
      "learning_rate": 1.782363977485929e-05,
      "loss": 1.7044,
      "step": 7190
    },
    {
      "epoch": 4.5823389021479715,
      "grad_norm": 0.8696564435958862,
      "learning_rate": 1.7555615116590727e-05,
      "loss": 1.6653,
      "step": 7200
    },
    {
      "epoch": 4.5823389021479715,
      "eval_loss": 2.0945732593536377,
      "eval_runtime": 148.1933,
      "eval_samples_per_second": 4.717,
      "eval_steps_per_second": 0.594,
      "step": 7200
    },
    {
      "epoch": 4.588703261734288,
      "grad_norm": 1.1357810497283936,
      "learning_rate": 1.728759045832217e-05,
      "loss": 1.671,
      "step": 7210
    },
    {
      "epoch": 4.595067621320605,
      "grad_norm": 0.9073346257209778,
      "learning_rate": 1.7019565800053606e-05,
      "loss": 1.694,
      "step": 7220
    },
    {
      "epoch": 4.601431980906922,
      "grad_norm": 1.0234146118164062,
      "learning_rate": 1.6751541141785048e-05,
      "loss": 1.6264,
      "step": 7230
    },
    {
      "epoch": 4.607796340493238,
      "grad_norm": 0.9241636395454407,
      "learning_rate": 1.6483516483516486e-05,
      "loss": 1.6859,
      "step": 7240
    },
    {
      "epoch": 4.614160700079554,
      "grad_norm": 1.196280837059021,
      "learning_rate": 1.6215491825247923e-05,
      "loss": 1.7383,
      "step": 7250
    },
    {
      "epoch": 4.620525059665871,
      "grad_norm": 0.9501188397407532,
      "learning_rate": 1.594746716697936e-05,
      "loss": 1.686,
      "step": 7260
    },
    {
      "epoch": 4.626889419252188,
      "grad_norm": 1.0379815101623535,
      "learning_rate": 1.56794425087108e-05,
      "loss": 1.7249,
      "step": 7270
    },
    {
      "epoch": 4.633253778838505,
      "grad_norm": 0.9927683472633362,
      "learning_rate": 1.541141785044224e-05,
      "loss": 1.7292,
      "step": 7280
    },
    {
      "epoch": 4.6396181384248205,
      "grad_norm": 1.1746894121170044,
      "learning_rate": 1.514339319217368e-05,
      "loss": 1.7232,
      "step": 7290
    },
    {
      "epoch": 4.645982498011137,
      "grad_norm": 1.1108922958374023,
      "learning_rate": 1.487536853390512e-05,
      "loss": 1.7842,
      "step": 7300
    },
    {
      "epoch": 4.652346857597454,
      "grad_norm": 0.8346616625785828,
      "learning_rate": 1.460734387563656e-05,
      "loss": 1.7584,
      "step": 7310
    },
    {
      "epoch": 4.658711217183771,
      "grad_norm": 1.007897138595581,
      "learning_rate": 1.4339319217368e-05,
      "loss": 1.7167,
      "step": 7320
    },
    {
      "epoch": 4.6650755767700876,
      "grad_norm": 1.0013329982757568,
      "learning_rate": 1.4071294559099437e-05,
      "loss": 1.7899,
      "step": 7330
    },
    {
      "epoch": 4.671439936356404,
      "grad_norm": 0.855705738067627,
      "learning_rate": 1.3803269900830875e-05,
      "loss": 1.7376,
      "step": 7340
    },
    {
      "epoch": 4.677804295942721,
      "grad_norm": 0.8766506314277649,
      "learning_rate": 1.3535245242562316e-05,
      "loss": 1.6319,
      "step": 7350
    },
    {
      "epoch": 4.684168655529037,
      "grad_norm": 0.9233888387680054,
      "learning_rate": 1.3267220584293754e-05,
      "loss": 1.701,
      "step": 7360
    },
    {
      "epoch": 4.690533015115354,
      "grad_norm": 1.0399483442306519,
      "learning_rate": 1.2999195926025196e-05,
      "loss": 1.6737,
      "step": 7370
    },
    {
      "epoch": 4.6968973747016705,
      "grad_norm": 0.8847174644470215,
      "learning_rate": 1.2731171267756634e-05,
      "loss": 1.673,
      "step": 7380
    },
    {
      "epoch": 4.703261734287987,
      "grad_norm": 0.9967674612998962,
      "learning_rate": 1.2463146609488073e-05,
      "loss": 1.7216,
      "step": 7390
    },
    {
      "epoch": 4.709626093874304,
      "grad_norm": 0.8552480340003967,
      "learning_rate": 1.2195121951219513e-05,
      "loss": 1.6807,
      "step": 7400
    },
    {
      "epoch": 4.709626093874304,
      "eval_loss": 2.095301866531372,
      "eval_runtime": 148.0694,
      "eval_samples_per_second": 4.721,
      "eval_steps_per_second": 0.594,
      "step": 7400
    },
    {
      "epoch": 4.715990453460621,
      "grad_norm": 1.0687183141708374,
      "learning_rate": 1.1927097292950952e-05,
      "loss": 1.6636,
      "step": 7410
    },
    {
      "epoch": 4.7223548130469375,
      "grad_norm": 1.0471910238265991,
      "learning_rate": 1.1659072634682392e-05,
      "loss": 1.7015,
      "step": 7420
    },
    {
      "epoch": 4.728719172633253,
      "grad_norm": 0.9060522317886353,
      "learning_rate": 1.139104797641383e-05,
      "loss": 1.7172,
      "step": 7430
    },
    {
      "epoch": 4.73508353221957,
      "grad_norm": 1.038069248199463,
      "learning_rate": 1.112302331814527e-05,
      "loss": 1.6912,
      "step": 7440
    },
    {
      "epoch": 4.741447891805887,
      "grad_norm": 1.2451038360595703,
      "learning_rate": 1.085499865987671e-05,
      "loss": 1.6216,
      "step": 7450
    },
    {
      "epoch": 4.747812251392204,
      "grad_norm": 0.8268951177597046,
      "learning_rate": 1.0586974001608147e-05,
      "loss": 1.6296,
      "step": 7460
    },
    {
      "epoch": 4.75417661097852,
      "grad_norm": 0.8990687131881714,
      "learning_rate": 1.0318949343339587e-05,
      "loss": 1.6748,
      "step": 7470
    },
    {
      "epoch": 4.760540970564837,
      "grad_norm": 1.3926115036010742,
      "learning_rate": 1.0050924685071027e-05,
      "loss": 1.7034,
      "step": 7480
    },
    {
      "epoch": 4.766905330151154,
      "grad_norm": 0.8620793223381042,
      "learning_rate": 9.782900026802466e-06,
      "loss": 1.6717,
      "step": 7490
    },
    {
      "epoch": 4.77326968973747,
      "grad_norm": 0.9877141118049622,
      "learning_rate": 9.514875368533906e-06,
      "loss": 1.8373,
      "step": 7500
    },
    {
      "epoch": 4.7796340493237865,
      "grad_norm": 1.0133558511734009,
      "learning_rate": 9.246850710265345e-06,
      "loss": 1.672,
      "step": 7510
    },
    {
      "epoch": 4.785998408910103,
      "grad_norm": 0.9752835631370544,
      "learning_rate": 8.978826051996785e-06,
      "loss": 1.6524,
      "step": 7520
    },
    {
      "epoch": 4.79236276849642,
      "grad_norm": 0.8257481455802917,
      "learning_rate": 8.710801393728225e-06,
      "loss": 1.6568,
      "step": 7530
    },
    {
      "epoch": 4.798727128082737,
      "grad_norm": 0.9259494543075562,
      "learning_rate": 8.442776735459663e-06,
      "loss": 1.6531,
      "step": 7540
    },
    {
      "epoch": 4.805091487669054,
      "grad_norm": 1.2920159101486206,
      "learning_rate": 8.174752077191102e-06,
      "loss": 1.7246,
      "step": 7550
    },
    {
      "epoch": 4.81145584725537,
      "grad_norm": 1.0446444749832153,
      "learning_rate": 7.90672741892254e-06,
      "loss": 1.7085,
      "step": 7560
    },
    {
      "epoch": 4.817820206841686,
      "grad_norm": 1.1714465618133545,
      "learning_rate": 7.63870276065398e-06,
      "loss": 1.7303,
      "step": 7570
    },
    {
      "epoch": 4.824184566428003,
      "grad_norm": 1.0016043186187744,
      "learning_rate": 7.37067810238542e-06,
      "loss": 1.6007,
      "step": 7580
    },
    {
      "epoch": 4.83054892601432,
      "grad_norm": 0.9309627413749695,
      "learning_rate": 7.102653444116859e-06,
      "loss": 1.6722,
      "step": 7590
    },
    {
      "epoch": 4.8369132856006365,
      "grad_norm": 1.19844388961792,
      "learning_rate": 6.834628785848299e-06,
      "loss": 1.7331,
      "step": 7600
    },
    {
      "epoch": 4.8369132856006365,
      "eval_loss": 2.098222017288208,
      "eval_runtime": 148.1179,
      "eval_samples_per_second": 4.719,
      "eval_steps_per_second": 0.594,
      "step": 7600
    },
    {
      "epoch": 4.843277645186953,
      "grad_norm": 0.9811587333679199,
      "learning_rate": 6.566604127579738e-06,
      "loss": 1.6658,
      "step": 7610
    },
    {
      "epoch": 4.84964200477327,
      "grad_norm": 0.9312347173690796,
      "learning_rate": 6.298579469311176e-06,
      "loss": 1.6488,
      "step": 7620
    },
    {
      "epoch": 4.856006364359587,
      "grad_norm": 0.9883821606636047,
      "learning_rate": 6.030554811042617e-06,
      "loss": 1.6437,
      "step": 7630
    },
    {
      "epoch": 4.862370723945903,
      "grad_norm": 0.8966830372810364,
      "learning_rate": 5.7625301527740555e-06,
      "loss": 1.6648,
      "step": 7640
    },
    {
      "epoch": 4.868735083532219,
      "grad_norm": 1.1219450235366821,
      "learning_rate": 5.494505494505494e-06,
      "loss": 1.6468,
      "step": 7650
    },
    {
      "epoch": 4.875099443118536,
      "grad_norm": 1.0466772317886353,
      "learning_rate": 5.226480836236934e-06,
      "loss": 1.762,
      "step": 7660
    },
    {
      "epoch": 4.881463802704853,
      "grad_norm": 0.9995772242546082,
      "learning_rate": 4.958456177968374e-06,
      "loss": 1.6511,
      "step": 7670
    },
    {
      "epoch": 4.88782816229117,
      "grad_norm": 0.9609196186065674,
      "learning_rate": 4.690431519699812e-06,
      "loss": 1.6721,
      "step": 7680
    },
    {
      "epoch": 4.894192521877486,
      "grad_norm": 1.0295500755310059,
      "learning_rate": 4.422406861431252e-06,
      "loss": 1.6532,
      "step": 7690
    },
    {
      "epoch": 4.900556881463803,
      "grad_norm": 0.9810314178466797,
      "learning_rate": 4.154382203162692e-06,
      "loss": 1.6656,
      "step": 7700
    },
    {
      "epoch": 4.906921241050119,
      "grad_norm": 1.0082776546478271,
      "learning_rate": 3.8863575448941304e-06,
      "loss": 1.6886,
      "step": 7710
    },
    {
      "epoch": 4.913285600636436,
      "grad_norm": 1.0208871364593506,
      "learning_rate": 3.6183328866255696e-06,
      "loss": 1.6345,
      "step": 7720
    },
    {
      "epoch": 4.919649960222753,
      "grad_norm": 1.015578031539917,
      "learning_rate": 3.350308228357009e-06,
      "loss": 1.67,
      "step": 7730
    },
    {
      "epoch": 4.926014319809069,
      "grad_norm": 0.9569914937019348,
      "learning_rate": 3.0822835700884485e-06,
      "loss": 1.7047,
      "step": 7740
    },
    {
      "epoch": 4.932378679395386,
      "grad_norm": 0.9207568764686584,
      "learning_rate": 2.8142589118198877e-06,
      "loss": 1.6096,
      "step": 7750
    },
    {
      "epoch": 4.938743038981702,
      "grad_norm": 1.0855963230133057,
      "learning_rate": 2.546234253551327e-06,
      "loss": 1.7334,
      "step": 7760
    },
    {
      "epoch": 4.945107398568019,
      "grad_norm": 0.9866523742675781,
      "learning_rate": 2.278209595282766e-06,
      "loss": 1.6462,
      "step": 7770
    },
    {
      "epoch": 4.9514717581543355,
      "grad_norm": 0.9466951489448547,
      "learning_rate": 2.0101849370142053e-06,
      "loss": 1.6856,
      "step": 7780
    },
    {
      "epoch": 4.957836117740652,
      "grad_norm": 0.846892237663269,
      "learning_rate": 1.7421602787456445e-06,
      "loss": 1.6833,
      "step": 7790
    },
    {
      "epoch": 4.964200477326969,
      "grad_norm": 0.862438976764679,
      "learning_rate": 1.4741356204770841e-06,
      "loss": 1.6663,
      "step": 7800
    },
    {
      "epoch": 4.964200477326969,
      "eval_loss": 2.0965912342071533,
      "eval_runtime": 148.0145,
      "eval_samples_per_second": 4.723,
      "eval_steps_per_second": 0.595,
      "step": 7800
    },
    {
      "epoch": 4.970564836913286,
      "grad_norm": 0.9151203036308289,
      "learning_rate": 1.2061109622085234e-06,
      "loss": 1.6277,
      "step": 7810
    },
    {
      "epoch": 4.9769291964996025,
      "grad_norm": 0.9592738151550293,
      "learning_rate": 9.380863039399626e-07,
      "loss": 1.6344,
      "step": 7820
    },
    {
      "epoch": 4.983293556085918,
      "grad_norm": 0.9345914125442505,
      "learning_rate": 6.700616456714018e-07,
      "loss": 1.7598,
      "step": 7830
    },
    {
      "epoch": 4.989657915672235,
      "grad_norm": 0.8472293019294739,
      "learning_rate": 4.020369874028411e-07,
      "loss": 1.6383,
      "step": 7840
    },
    {
      "epoch": 4.996022275258552,
      "grad_norm": 1.0251851081848145,
      "learning_rate": 1.3401232913428037e-07,
      "loss": 1.7164,
      "step": 7850
    }
  ],
  "logging_steps": 10,
  "max_steps": 7855,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9028315285159936e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
